{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as db\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score,explained_variance_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying birds that strongly select for one or more habitats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_userName = 'Tanag3r'\n",
    "ebird_token = 'j6c7l80ga2ib'\n",
    "db_name = 'trailheadDirectBirds_sous.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "##connect to database\n",
    "def connectDB():\n",
    "    try:\n",
    "        cnx = db.connect(db_name)\n",
    "    except Exception as cnxError:\n",
    "        raise UserWarning(f'Unable to connect to database due to: {cnxError}')\n",
    "    return cnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO #99 replace the update latestUpdate in the function with a trigger in the database\n",
    "class notInTable(ValueError):\n",
    "    def __init__(self,locId,message=\"given locId cannot be found in table Hotspots\"):\n",
    "        self.locId = locId\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n",
    "    def __str__(self):\n",
    "        return f'{self.locId} >> {self.message}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class emptyReturn(TypeError):\n",
    "    \n",
    "    def check_speciesCode(self,speciesCode: str,cnx):\n",
    "        cursor = cnx.cursor()\n",
    "        checkQuery = \"\"\"SELECT EXISTS(SELECT ? FROM historicObservations WHERE speciesCode = ?);\"\"\"\n",
    "        checkTuple = (speciesCode,speciesCode)\n",
    "        checkResult = cursor.execute(checkQuery,checkTuple).fetchone()[0]\n",
    "        if checkResult == 0:\n",
    "            message = f\"{speciesCode}: the given species code is not in the database\"\n",
    "        else:\n",
    "            message = \"no values have been returned by the query\"\n",
    "        return message\n",
    "    def __init__(self,queryRetrun,speciesCode,cnx):\n",
    "        self.queryRetrun = queryRetrun\n",
    "        self.speciesCode = speciesCode\n",
    "        self.cnx = cnx\n",
    "        self.message = self.check_speciesCode(speciesCode=speciesCode,cnx=cnx)\n",
    "        super().__init__(self.message)\n",
    "    def __str__(self):\n",
    "        return f'{self.check_speciesCode}'\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "habab = pd.read_sql(sql=\"\"\"with habitatAbundance as (\n",
    "select\n",
    "\tdate(obsDt) as \"obsDt\",\n",
    "\t(strftime('%Y',obsDt)||'-'||strftime('%W',obsDt)) as \"year_week\",\n",
    "\tround(avg(howMany),0) as \"habitatVolume\",\n",
    "\t(total(round(avg(howMany),0)) over(partition by strftime('%Y',obsDt)||'-'||strftime('%W',obsDt))) as \"volume_allHabitats\",\n",
    "\thabitatLabel \n",
    "from historicObservations as hsob\n",
    "left join (select locId,habitatLabel from Hotspots) as \"labels\" on hsob.locId=labels.locId\n",
    "where speciesCode = 'westan'\n",
    "group by year_week,habitatLabel\n",
    ")\n",
    "select obsDt,year_week,habitatVolume,round((habitatVolume/volume_allHabitats),2) as \"selectionRatio_\"\n",
    "from habitatAbundance\n",
    "where habitatLabel = 2\n",
    ";\"\"\",con=connectDB())\n",
    "habab.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def post_hotspotHabitat(locId: str,label: int,cnx=connectDB()):\n",
    "    try:\n",
    "        cursor = cnx.cursor()\n",
    "    #validate\n",
    "        validate_query = \"SELECT EXISTS(SELECT ? FROM Hotspots WHERE locId = ?)\"\n",
    "        validate_tuple = (locId,locId)\n",
    "        cursor.execute(validate_query,validate_tuple)\n",
    "        validate = cursor.fetchone()[0]\n",
    "        if validate == 0:\n",
    "            raise notInTable(locId)\n",
    "        else:\n",
    "            updateLabel_script = \"UPDATE Hotspots SET habitatLabel = ?, latestUpdate = ? WHERE locId = ?;\"\n",
    "            updatelabel_tuple = (label,str(dt.datetime.today()),locId)\n",
    "            cursor.execute(updateLabel_script,updatelabel_tuple)\n",
    "            cnx.commit()\n",
    "            cursor.close()\n",
    "    except ValueError as vxf:\n",
    "        raise vxf\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return locId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#derive habitat cluster labels from FAO values\n",
    "def kmeans_habitat(distinctHabitats: int,cnx= connectDB()):\n",
    "    try:\n",
    "        data = pd.read_sql(sql='SELECT * FROM FAO_by_locId;',con=cnx)\n",
    "        data = data.drop(columns=['locName']).set_index('locId')\n",
    "        data.fillna(0,inplace=True)\n",
    "    #normalize\n",
    "        maxValue = data.apply(max,axis=1)\n",
    "        data = data.apply(lambda x: (x/maxValue[x.index]),axis=0)   #min-max normalizing to smooth in proportionality\n",
    "    #compute kmeans for each locId\n",
    "        habitat_kmeans = KMeans(n_clusters=distinctHabitats,init='k-means++')\n",
    "        habitat_kmeans = habitat_kmeans.fit(data.values)\n",
    "        clusterLabels = habitat_kmeans.labels_\n",
    "        centerPoints = habitat_kmeans.cluster_centers_\n",
    "    #define habitats\n",
    "        habitatFrame = pd.DataFrame(data=clusterLabels,columns=['clusterLabel'],index=data.index).sort_values(by='clusterLabel').reset_index()\n",
    "        #habitatFrame = pd.merge(left=habitatFrame,left_on='locId',right=data,right_on='locId',how='left')\n",
    "    except Exception as kmeansExc:\n",
    "        raise kmeansExc\n",
    "    return habitatFrame,centerPoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test and interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO #100 write a function to test for seasonal preference with a scaling lead-lag scope dependent on volume of observations available\n",
    "query = f\"\"\"with habitatAbundance as (\n",
    "select\n",
    "\t(strftime('%Y',obsDt)||'-'||strftime('%W',obsDt)) as \"year_week\",\n",
    "\tround(avg(howMany),0) as \"habitatVolume\",\n",
    "\t(total(round(avg(howMany),0)) over(partition by strftime('%Y',obsDt)||'-'||strftime('%W',obsDt))) as \"volume_allHabitats\",\n",
    "\thabitatLabel \n",
    "from historicObservations as hsob\n",
    "left join (select locId,habitatLabel from Hotspots) as \"labels\" on hsob.locId=labels.locId\n",
    "where speciesCode = '{speciesCode}'\n",
    "group by year_week,habitatLabel\n",
    ")\n",
    "select year_week,round((habitatVolume/volume_allHabitats),2) as \"selectionRatio_{i}\"\n",
    "from habitatAbundance\n",
    "where habitatLabel = {i}\n",
    ";\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datebase(speciesCode,con = connectDB()):\n",
    "    try:\n",
    "        cursor = con.cursor()\n",
    "        minDateQuery = f\"\"\"select date(obsDt) as \"startDate\" from historicObservations group by speciesCode having obsDt=min(obsDt) and speciesCode = '{speciesCode}';\"\"\"\n",
    "        maxDateQuery = f\"\"\"select date(obsDt) as \"stopDate\" from historicObservations group by speciesCode having obsDt=max(obsDt) and speciesCode = '{speciesCode}';\"\"\"\n",
    "        testreturn = cursor.execute(minDateQuery).fetchone()\n",
    "        #minDate = cursor.execute(minDateQuery).fetchone()[0]\n",
    "        #maxDate = cursor.execute(maxDateQuery).fetchone()[0]\n",
    "        #datebase = []\n",
    "        #for i in pd.date_range(start=minDate,end=maxDate,freq='D',name='dates'):\n",
    "                #dates = i.astype('date64[ns]')\n",
    "                #datebase.append(i)\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return type(testreturn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#todo seasonality test on compiled selection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_datebase(speciesCode='westa')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce2b8b10e8082f390f0f7c9c12f304c9df3ed4554edd4b21c0fcee2d9ef65582"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
