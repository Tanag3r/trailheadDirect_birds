{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import json\n",
    "import requests\n",
    "import base64\n",
    "import sqlite3 as db\n",
    "sys.path.append('../')\n",
    "\n",
    "pd.options.display.max_rows = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_userName = 'Tanag3r'\n",
    "ebird_token = 'j6c7l80ga2ib'\n",
    "db_name = 'trailheadDirectBirds_sous.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##connect to database\n",
    "def connectDB():\n",
    "    try:\n",
    "        cnx = db.connect(db_name)\n",
    "    except Exception as cnxError:\n",
    "        raise UserWarning(f'Unable to connect to database due to: {cnxError}')\n",
    "    return cnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrailheadRef():\n",
    "    trailheadRef = pd.DataFrame()\n",
    "    cnx = connectDB()\n",
    "    try:\n",
    "        trailheadRef = pd.read_sql('select * from trailheadRef;',con=cnx)\n",
    "        trailheadRef.set_index('index',inplace=True)\n",
    "        trailheadRef.convert_dtypes()\n",
    "    except db.DatabaseError as dbError:\n",
    "        print(dbError)\n",
    "    cnx.close()\n",
    "    return trailheadRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "trailheadRef = getTrailheadRef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  For the sake of demonstration please assume the data in the 'trailheadRef' comes from a King County Metro service\n",
    "##  and/or is user-provided so some cleaning is required\n",
    "def clean_trailheadRef(Latitude: float,Longitude: float, Address: str):\n",
    "    cnx = connectDB()\n",
    "    cur = cnx.cursor()\n",
    "    trailheads = getTrailheadRef()\n",
    "    ##set types for error checking, other cleaning\n",
    "    trailheads.Latitude = trailheads['Latitude'].fillna(0.00).astype('float64',errors='ignore')\n",
    "    trailheads.Longitude = trailheads['Longitude'].fillna(0.00).astype('float64',errors='ignore')\n",
    "    trailheads.Address = trailheads['Address'].astype(str)\n",
    "\n",
    "    updateMask = trailheads.apply(lambda x: bool(x.Address.strip()) and (x.Latitude == 0.00) and (x.Longitude == 0.00),axis=1)\n",
    "    ##write stops that fail the updateMask checks to the db as logs\n",
    "    try:\n",
    "        trailheads[updateMask].copy().to_sql('geo_errorLogs',con=cnx,if_exists='append')\n",
    "    except db.DatabaseError as dbError:\n",
    "        cur.execute('INSERT INTO sql_errorLogs VALUES (?, ?)',dbError,str(dt.date.today()))\n",
    "    cnx.close()\n",
    "    return trailheads[~updateMask]\n",
    "    \n",
    "\n",
    "    ##needsGeo = trailheads[updateMask].copy()\n",
    "    ##TODO: #25 fetch coordinates of trailheads in the update mask using Nominatim address service\n",
    "    ##TODO #48 merge or call results of clean_trailheadRef() with dropCases()\n",
    "#def dropCases():\n",
    "    #dropCase = clean_trailheadRef()\n",
    "    #dropMask = dropCase.apply(lambda y: (y.Address == '') | (y.Address == 'None'),axis=1)\n",
    "    #noGeo = [y for y in list(dropCase[dropMask].StopName) if y!='']\n",
    "    #if noGeo:\n",
    "        #raise Exception('unable to fetch coordinates for {\",\".join(noGeo)}')\n",
    "    #return dropCase[~dropMask]\n",
    "    ##if there is no address or coordinates, drop the line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trailhead eBird hotspot update\n",
    "\n",
    "1. Ask the eBird API for the latest list of hotspots for each trailhead\n",
    "2. Add new eBird hotspots to the table 'Hotspots' in the trailheadDirectBirds_sous database\n",
    "3. Update hotspot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trailheadHotspots(radius: int = 4,fmt: str = 'json'):\n",
    "    cleanTrailheads = pd.DataFrame(clean_trailheadRef(trailheadRef.Latitude,trailheadRef.Longitude,trailheadRef.Address))\n",
    "    import time\n",
    "    trailheadHotspots = []\n",
    "    try:\n",
    "        for StopName in cleanTrailheads.itertuples():\n",
    "            time.sleep(0.3)\n",
    "            ebird_url = 'https://api.ebird.org/v2/ref/hotspot/geo?'\n",
    "            ebird_auth_header = {'X-eBirdApiToken': ebird_token}\n",
    "            ebird_params = {\n",
    "                'lat': str(StopName.Latitude),\n",
    "                'lng': str(StopName.Longitude),\n",
    "                'dist': str(radius),\n",
    "                'fmt': str(fmt)\n",
    "            }\n",
    "            ebird_request = requests.get(ebird_url,headers=ebird_auth_header,params=ebird_params)\n",
    "            ebird_response = pd.DataFrame(ebird_request.json())\n",
    "            if ebird_request.status_code == requests.codes.ok:\n",
    "                ebird_response['StopName'] = StopName.StopName\n",
    "                trailheadHotspots.append(ebird_response)\n",
    "            ebird_request.raise_for_status()\n",
    "    except Exception as ee:\n",
    "        raise UserWarning(ee)\n",
    "    all_trailheadHotspots = pd.DataFrame()\n",
    "    all_trailheadHotspots = pd.concat(trailheadHotspots,ignore_index=True)\n",
    "    return all_trailheadHotspots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hotspots = get_trailheadHotspots()\n",
    "\n",
    "def update_trailheadHotspots():\n",
    "    cnx = connectDB()\n",
    "    new_hotspots = pd.DataFrame(get_trailheadHotspots())\n",
    "    ##new_hotspots = pd.DataFrame(hotspots)\n",
    "    new_hotspots['latestUpdate'] = dt.datetime.today()\n",
    "    try:\n",
    "        current_hotspots = pd.DataFrame()\n",
    "        current_hotspots = pd.read_sql('select * from hotspots',cnx,parse_dates=[\"latestObsDt\",\"latestUpdate\"])\n",
    "        current_hotspots.set_index('index',inplace=True)\n",
    "    except Exception as ex:\n",
    "        raise UserWarning(ex.__cause__)\n",
    "    else:\n",
    "        frames = [new_hotspots,current_hotspots]\n",
    "        all_hotspots = pd.concat(frames,ignore_index=True)\n",
    "        all_hotspots.sort_values(by=['StopName','locId','latestObsDt','latestUpdate'],ascending=False,inplace=True)\n",
    "        all_hotspots.drop_duplicates(subset=['StopName','locId'],keep='first',inplace=True)\n",
    "        all_hotspots.to_sql(name='Hotspots_cooking',con=cnx,if_exists='append')\n",
    "        cnx.close()\n",
    "    return all_hotspots"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce2b8b10e8082f390f0f7c9c12f304c9df3ed4554edd4b21c0fcee2d9ef65582"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
