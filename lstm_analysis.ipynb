{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "import sqlite3 as db\n",
    "import datetime as dt\n",
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_userName = 'Tanag3r'\n",
    "ebird_token = 'j6c7l80ga2ib'\n",
    "db_name = 'trailheadDirectBirds_sous.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "##connect to database\n",
    "def connectDB():\n",
    "    try:\n",
    "        cnx = db.connect(db_name)\n",
    "    except Exception as cnxError:\n",
    "        raise UserWarning(f'Unable to connect to database due to: {cnxError}')\n",
    "    return cnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline request from the application layer\n",
    "#outputs a list of birds at the stop and a classification based solely off the number of observations\n",
    "def birdList_request(StopName: str,cnx):\n",
    "    try:\n",
    "        query = f'SELECT speciesCode,count(subId) as \"checklists\",(SELECT count(subId) FROM historicObservations hxobx WHERE hxobx.speciesCode=hsob.speciesCode) as \"sightings\" FROM historicObservations hsob LEFT JOIN closestStop on hsob.locId=closestStop.locId WHERE StopName = \"{StopName}\" GROUP BY speciesCode;'\n",
    "        sightings = pd.read_sql(sql=query,con=cnx)\n",
    "    #rareness at the stop\n",
    "        sightings['stopGroup'] = int\n",
    "        bucket = sightings['checklists'].quantile([0,0.15,0.5,0.85,1])\n",
    "        sightings.loc[sightings['checklists'] <= bucket[0.15],'stopGroup'] = 1  #mythic\n",
    "        sightings.loc[(sightings['checklists'] > bucket[0.15]) & (sightings['checklists'] <= bucket[0.5]),'stopGroup'] = 2  #rare\n",
    "        sightings.loc[(sightings['checklists'] > bucket[0.5]) & (sightings['checklists'] < bucket[0.85]),'stopGroup'] = 3   #uncommon\n",
    "        sightings.loc[(sightings['checklists'] >= bucket[0.85]) & (sightings['checklists'] <=bucket[1]),'stopGroup'] = 4    #common\n",
    "    #overall rareness\n",
    "        sightings['overall'] = int\n",
    "        bucket = sightings['sightings'].quantile([0,0.15,0.5,0.85,1])\n",
    "        sightings.loc[sightings['sightings'] <= bucket[0.15],'overall'] = 1\n",
    "        sightings.loc[(sightings['sightings'] > bucket[0.15]) & (sightings['sightings'] <= bucket[0.5]),'overall'] = 2\n",
    "        sightings.loc[(sightings['sightings'] > bucket[0.5]) & (sightings['sightings'] < bucket[0.85]),'overall'] = 3\n",
    "        sightings.loc[(sightings['sightings'] >= bucket[0.85]) & (sightings['sightings'] <=bucket[1]),'overall'] = 4\n",
    "        sightings['StopName'] = StopName\n",
    "    #raise an exception if the stopName given is not valid and return a list of valid stop names\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return sightings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM analysis of common birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonCore = birdList_request(StopName='EastSunsetWay',cnx=connectDB())\n",
    "commonCore = commonCore[commonCore.apply(lambda x: (x['stopGroup']==4) and (x['overall']==4),axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speciesCode</th>\n",
       "      <th>checklists</th>\n",
       "      <th>sightings</th>\n",
       "      <th>stopGroup</th>\n",
       "      <th>overall</th>\n",
       "      <th>StopName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amecro</td>\n",
       "      <td>91</td>\n",
       "      <td>293</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EastSunsetWay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amerob</td>\n",
       "      <td>80</td>\n",
       "      <td>371</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EastSunsetWay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>annhum</td>\n",
       "      <td>40</td>\n",
       "      <td>245</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EastSunsetWay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bkcchi</td>\n",
       "      <td>68</td>\n",
       "      <td>281</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EastSunsetWay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chbchi</td>\n",
       "      <td>41</td>\n",
       "      <td>237</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EastSunsetWay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>daejun</td>\n",
       "      <td>95</td>\n",
       "      <td>419</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EastSunsetWay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>gockin</td>\n",
       "      <td>36</td>\n",
       "      <td>179</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EastSunsetWay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>mallar3</td>\n",
       "      <td>91</td>\n",
       "      <td>253</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EastSunsetWay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>norfli</td>\n",
       "      <td>26</td>\n",
       "      <td>201</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EastSunsetWay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>pacwre1</td>\n",
       "      <td>42</td>\n",
       "      <td>203</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EastSunsetWay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>sonspa</td>\n",
       "      <td>84</td>\n",
       "      <td>323</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EastSunsetWay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>spotow</td>\n",
       "      <td>48</td>\n",
       "      <td>285</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EastSunsetWay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>stejay</td>\n",
       "      <td>33</td>\n",
       "      <td>203</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EastSunsetWay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speciesCode  checklists  sightings stopGroup overall       StopName\n",
       "0       amecro          91        293         4       4  EastSunsetWay\n",
       "4       amerob          80        371         4       4  EastSunsetWay\n",
       "5       annhum          40        245         4       4  EastSunsetWay\n",
       "11      bkcchi          68        281         4       4  EastSunsetWay\n",
       "25      chbchi          41        237         4       4  EastSunsetWay\n",
       "29      daejun          95        419         4       4  EastSunsetWay\n",
       "38      gockin          36        179         4       4  EastSunsetWay\n",
       "56     mallar3          91        253         4       4  EastSunsetWay\n",
       "59      norfli          26        201         4       4  EastSunsetWay\n",
       "66     pacwre1          42        203         4       4  EastSunsetWay\n",
       "84      sonspa          84        323         4       4  EastSunsetWay\n",
       "85      spotow          48        285         4       4  EastSunsetWay\n",
       "86      stejay          33        203         4       4  EastSunsetWay"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dailyDataset(speciesCode: str,StopName: str,cnx = connectDB()):\n",
    "    try:\n",
    "        query = f'SELECT speciesCode,FX.locId,StopName,obsDt,howMany FROM historicObservations AS FX LEFT JOIN closestStop on FX.locId = closestStop.locId WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.speciesCode = \"{speciesCode}\" AND StopName = \"{StopName}\";'\n",
    "        obsData = pd.read_sql(query,con=cnx,parse_dates=['obsDt'])\n",
    "        obsData.set_index('obsDt',inplace=True)\n",
    "    #resample to days\n",
    "        dailyData = obsData.resample('d')\n",
    "        dailyData = dailyData.mean()\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return dailyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "querySpecies = 'daejun'\n",
    "StopName = 'EastSunsetWay'\n",
    "query = f'SELECT speciesCode,FX.locId,StopName,obsDt,howMany FROM historicObservations AS FX LEFT JOIN closestStop on FX.locId = closestStop.locId WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.speciesCode = \"{querySpecies}\" AND StopName = \"{StopName}\";'\n",
    "obsData = pd.read_sql(query,con=connectDB(),parse_dates=['obsDt'])\n",
    "obsData.set_index('obsDt',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>howMany</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obsDt</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-06</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-07</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-08</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-09</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-10</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1163 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            howMany\n",
       "obsDt              \n",
       "2019-01-03     24.0\n",
       "2019-01-04      NaN\n",
       "2019-01-05      NaN\n",
       "2019-01-06      NaN\n",
       "2019-01-07      NaN\n",
       "...             ...\n",
       "2022-03-06      NaN\n",
       "2022-03-07      NaN\n",
       "2022-03-08      NaN\n",
       "2022-03-09      NaN\n",
       "2022-03-10      1.0\n",
       "\n",
       "[1163 rows x 1 columns]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obsDataDaily = obsData.resample('d')\n",
    "dailyData = obsDataDaily.mean()\n",
    "dailyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO build realtime prediction function using LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_interpolatedDataset(dailyData:pd.DataFrame):\n",
    "    try:\n",
    "    #mask in null presence\n",
    "        dailyData['mask'] = dailyData['howMany'].interpolate(method='zero',limit_direction='both',limit=21)\n",
    "        dailyData.loc[(dailyData['mask'].isna() == True),'howMany'] = 0\n",
    "        test_dailyData = dailyData[dailyData['howMany'].notna()].drop(columns='mask')\n",
    "        \n",
    "#determine the best method of interpolation for the given data\n",
    "        testResults = []\n",
    "        methodDict = [{'method':'linear','order':3,'limit_direction':'both','limit':21},{'method':'slinear','order':3,'limit_direction':'both','limit':21},{'method':'quadratic','order':0,'limit_direction':'both','limit':21},{'method':'cubic','order':3,'limit_direction':'both','limit':21},{'method':'spline','order':3,'limit_direction':'both','limit':21},{'method':'spline','order':5,'limit_direction':'both','limit':21},{'method':'polynomial','order':3,'limit_direction':'both','limit':21},{'method':'polynomial','order':5,'limit_direction':'both','limit':21}]\n",
    "        for v in list([0.2,0.25,0.3,0.35]):\n",
    "            test_dailyData['sample'] = test_dailyData['howMany'].sample(frac=v,random_state=1)\n",
    "            blob = {}\n",
    "            for test in methodDict:\n",
    "                testName = str(test['method'])\n",
    "                test_dailyData[testName] = test_dailyData['sample']\n",
    "                test_dailyData[testName] = test_dailyData['sample'].interpolate(method=test['method'],order=test['order'],limit=test['limit'],limit_direction=test['limit_direction']).fillna(test_dailyData['howMany'])\n",
    "                r_sqr = r2_score(y_true=test_dailyData['howMany'],y_pred=test_dailyData[testName])\n",
    "                if r_sqr < 0:\n",
    "                    continue\n",
    "                blob = {'method':test['method'],'order':test['order'],'limit':test['limit'],'sampleSize':v,'r_sqr':r_sqr}\n",
    "                testResults.append(blob)\n",
    "        if not testResults:\n",
    "            testResults.append({'method':'nearest','order':0,'limit':21})\n",
    "            resultFrame = pd.DataFrame.from_dict(testResults)\n",
    "        else:\n",
    "            resultFrame = pd.DataFrame.from_dict(testResults)\n",
    "            resultFrame = resultFrame.groupby(by=['method','order','limit'])['r_sqr'].median().reset_index()\n",
    "            resultFrame.sort_values(by=['r_sqr'],ascending=False,inplace=True,ignore_index=True)\n",
    "    #apply the best interpolation method\n",
    "        bestMethod = resultFrame.loc[0].to_dict()\n",
    "        dailyData['howMany'] = dailyData['howMany'].interpolate(method=bestMethod['method'],order=bestMethod['order'],limit=bestMethod['limit'],limit_direction='both')\n",
    "        dailyData.drop(columns='mask',inplace=True)\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return dailyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_DatasetDates(dailyData: pd.DataFrame):\n",
    "    try:\n",
    "        if (len(dailyData)/7).is_integer()!=True:\n",
    "            i = 0\n",
    "            for i in range(1,6):\n",
    "                dailyDataCut = dailyData[i:]\n",
    "                if (len(dailyDataCut)/7).is_integer()==True:\n",
    "                    dailyDataCut\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "        else:\n",
    "            pass\n",
    "    except Exception as ee:\n",
    "        raise ee\n",
    "    return dailyDataCut     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trainTest(dailyObs):\n",
    "    dailyObs = trim_DatasetDates(dailyData=dailyObs)\n",
    "    train, test = dailyObs[1:-328],dailyObs[-328:-6]\n",
    "    train = np.array(np.split(train,len(train)/7))\n",
    "    test = np.array(np.split(test,len(test)/7))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build forward-moving windows\n",
    "def to_supervised(train,nInput,nOut = 7):\n",
    "    train = train.reshape((train.shape[0]*train.shape[1],train.shape[2]))\n",
    "    X, y = [],[]\n",
    "    inStart = 0\n",
    "    for _ in range(len(train)):\n",
    "        inEnd = inStart + nInput\n",
    "        outEnd = inEnd + nOut\n",
    "        if outEnd <= len(train):\n",
    "            xIn = train[inStart:inEnd,0]\n",
    "            xIn = xIn.reshape((len(xIn),1))\n",
    "            X.append(xIn)\n",
    "            y.append(train[inEnd:outEnd,0])\n",
    "        inStart+= 1\n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_basicModel(train,nInput):\n",
    "    train_x,train_y = to_supervised(train,nInput)\n",
    "    verbose, epochs, batch_size = 0,70,16\n",
    "    nTimesteps,nFeatures,nOutputs = train_x.shape[1],train_x.shape[2],train_y.shape[1]\n",
    "    model = Sequential()\n",
    "    #model.add(Bidirectional(LSTM(units=200,activation='relu')))\n",
    "    model.add(LSTM(units=200,activation='relu', input_shape=(nTimesteps,nFeatures)))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(nOutputs))\n",
    "    model.compile(loss='mse',optimizer='adam')\n",
    "    model.fit(train_x,train_y,epochs=epochs,batch_size=batch_size,verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: build another model using encoder-decoder, run tests\n",
    "##TODO export models to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "amerob_eastSunset_model = build_basicModel(train=train,nInput=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "stejay_eastSunset_model = build_basicModel(train=train,nInput=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model,history,nInput):\n",
    "    histData = np.array(history)\n",
    "    #histData = np.array(np.split(histData,len(histData)/7))\n",
    "    histData = histData.reshape((histData.shape[0]*histData.shape[1],histData.shape[2]))\n",
    "    inputX = histData[-nInput:,0]\n",
    "    inputX = inputX.reshape((1,len(inputX),1))\n",
    "    yhat = model.predict(inputX,verbose=0)\n",
    "    yhat = yhat[0]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_forecasts(actual,predicted):\n",
    "    try:\n",
    "        scores = list()\n",
    "        for i in range(actual.shape[1]):\n",
    "            mse = mean_squared_error(actual[:,i],predicted[:,i])\n",
    "            rmse = np.sqrt(mse)\n",
    "            scores.append(rmse)\n",
    "        s = 0\n",
    "        for row in range(actual.shape[0]):\n",
    "            for col in range(actual.shape[1]):\n",
    "                s+= (actual[row,col] - predicted[row,col])**2\n",
    "        score = np.sqrt(s/(actual.shape[0]*actual.shape[1]))\n",
    "    except Exception as metricExc:\n",
    "        raise metricExc\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalModel(train,test,nInput):\n",
    "    model = build_basicModel(train=train,nInput=nInput)\n",
    "    history = [x for x in train]\n",
    "    predictions = []\n",
    "    for i in range(len(test)):\n",
    "        yhatSeq = forecast(model=model,history=history,nInput=nInput)\n",
    "        predictions.append(yhatSeq)\n",
    "        history.append(test[i,:])\n",
    "    predictions = np.array(predictions)\n",
    "    score, scores = eval_forecasts(actual=test[:,:,0],predicted=predictions)\n",
    "    return score, scores\n",
    "    #return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, scores = evalModel(train=train,test=test,nInput=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeEvalScore(name,score,scores):\n",
    "    sScores = ', '.join(['%f' % s for s in scores])\n",
    "    print('%s: [%.3f] %s' % (name, score, sScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run: [1.052] 1.003830, 0.517272, 0.763046, 0.948381, 1.110182, 1.257345, 1.473364\n"
     ]
    }
   ],
   "source": [
    "summarizeEvalScore(name='run',score=score,scores=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "amerob:\n",
    "1. run1: [2.551] 2.458957, 2.472114, 2.475770, 2.677192, 3.045214, 2.251491, 2.402137 n = 7\n",
    "2. run2: [2.655] 2.482476, 2.564362, 2.557338, 2.738337, 3.200391, 2.457562, 2.509320 n = 21\n",
    "3. run3: [3.221] 2.561701, 2.617324, 2.715710, 3.185073, 3.910806, 3.548933, 3.717976 n = 14\n",
    "4. run4: [2.757] 2.647477, 2.664606, 2.711631, 2.933634, 3.188165, 2.496027, 2.599233 n = 7 bidirectional\n",
    "5. run5: [2.216] 0.385453, 0.939606, 1.419237, 1.818103, 2.423542, 2.977693, 3.646165 n = 7 note: changed interpolation method to slinear\n",
    "6. run6: [2.442] 0.468001, 1.068273, 1.803750, 2.283598, 2.770545, 3.216125, 3.727616 n = 7\n",
    "7. run7: [2.146] 0.346224, 1.057628, 1.474756, 1.910932, 2.273262, 2.820911, 3.470625 n = 7\n",
    "8. run: [2.082] 0.474444, 0.973971, 1.394103, 1.790021, 2.196929, 2.821583, 3.353662 n = 7 improved interpolation method\n",
    "9. run: [2.770] 1.373590, 0.953020, 1.333994, 2.028866, 2.949500, 3.854387, 4.632758 n = 28 stick with a lower n\n",
    "\n",
    "stejay:\n",
    "1. run: [0.234] 0.171749, 0.185661, 0.209144, 0.226055, 0.248578, 0.272514, 0.297879 n = 7 for stejay\n",
    "\n",
    "daejun:\n",
    "1. run: [1.052] 1.003830, 0.517272, 0.763046, 0.948381, 1.110182, 1.257345, 1.473364 n = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO #94 build three-week forecasting method on top of LSTM model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce2b8b10e8082f390f0f7c9c12f304c9df3ed4554edd4b21c0fcee2d9ef65582"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
