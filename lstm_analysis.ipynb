{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "import sqlite3 as db\n",
    "import datetime as dt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_userName = 'Tanag3r'\n",
    "ebird_token = 'j6c7l80ga2ib'\n",
    "db_name = 'trailheadDirectBirds_sous.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "##connect to database\n",
    "def connectDB():\n",
    "    try:\n",
    "        cnx = db.connect(db_name)\n",
    "    except Exception as cnxError:\n",
    "        raise UserWarning(f'Unable to connect to database due to: {cnxError}')\n",
    "    return cnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline request from the application layer\n",
    "#outputs a list of birds at the stop and a classification based solely off the number of observations\n",
    "def birdList_request(StopName: str,cnx):\n",
    "    try:\n",
    "        query = f'SELECT speciesCode,count(subId) as \"checklists\",(SELECT count(subId) FROM historicObservations hxobx WHERE hxobx.speciesCode=hsob.speciesCode) as \"sightings\" FROM historicObservations hsob LEFT JOIN closestStop on hsob.locId=closestStop.locId WHERE StopName = \"{StopName}\" GROUP BY speciesCode;'\n",
    "        sightings = pd.read_sql(sql=query,con=cnx)\n",
    "    #rareness at the stop\n",
    "        sightings['stopGroup'] = int\n",
    "        bucket = sightings['checklists'].quantile([0,0.15,0.5,0.85,1])\n",
    "        sightings.loc[sightings['checklists'] <= bucket[0.15],'stopGroup'] = 1  #mythic\n",
    "        sightings.loc[(sightings['checklists'] > bucket[0.15]) & (sightings['checklists'] <= bucket[0.5]),'stopGroup'] = 2  #rare\n",
    "        sightings.loc[(sightings['checklists'] > bucket[0.5]) & (sightings['checklists'] < bucket[0.85]),'stopGroup'] = 3   #uncommon\n",
    "        sightings.loc[(sightings['checklists'] >= bucket[0.85]) & (sightings['checklists'] <=bucket[1]),'stopGroup'] = 4    #common\n",
    "    #overall rareness\n",
    "        sightings['overall'] = int\n",
    "        bucket = sightings['sightings'].quantile([0,0.15,0.5,0.85,1])\n",
    "        sightings.loc[sightings['sightings'] <= bucket[0.15],'overall'] = 1\n",
    "        sightings.loc[(sightings['sightings'] > bucket[0.15]) & (sightings['sightings'] <= bucket[0.5]),'overall'] = 2\n",
    "        sightings.loc[(sightings['sightings'] > bucket[0.5]) & (sightings['sightings'] < bucket[0.85]),'overall'] = 3\n",
    "        sightings.loc[(sightings['sightings'] >= bucket[0.85]) & (sightings['sightings'] <=bucket[1]),'overall'] = 4\n",
    "        sightings['StopName'] = StopName\n",
    "    #raise an exception if the stopName given is not valid and return a list of valid stop names\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return sightings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM analysis of common birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonCore = birdList_request(StopName='EastSunsetWay',cnx=connectDB())\n",
    "commonCore = commonCore[commonCore.apply(lambda x: (x['stopGroup']==4) and (x['overall']==4),axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "querySpecies = 'amerob'\n",
    "StopName = 'EastSunsetWay'\n",
    "query = f'SELECT speciesCode,FX.locId,StopName,obsDt,howMany FROM historicObservations AS FX LEFT JOIN closestStop on FX.locId = closestStop.locId WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.speciesCode = \"{querySpecies}\" AND StopName = \"{StopName}\";'\n",
    "obsData = pd.read_sql(query,con=connectDB(),parse_dates=['obsDt'])\n",
    "obsData.set_index('obsDt',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>howMany</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obsDt</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-03-23</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-24</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-25</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-26</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-27</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-06</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-07</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-08</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-09</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-10</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1084 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            howMany\n",
       "obsDt              \n",
       "2019-03-23      5.0\n",
       "2019-03-24      NaN\n",
       "2019-03-25      NaN\n",
       "2019-03-26      NaN\n",
       "2019-03-27      NaN\n",
       "...             ...\n",
       "2022-03-06      NaN\n",
       "2022-03-07      NaN\n",
       "2022-03-08      NaN\n",
       "2022-03-09      NaN\n",
       "2022-03-10     13.0\n",
       "\n",
       "[1084 rows x 1 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obsDataDaily = obsData.resample('d')\n",
    "dailyData = obsDataDaily.mean()\n",
    "dailyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO update to bidirectional model\n",
    "##TODO update LSTM from days of the week to weeks of the year\n",
    "##TODO build realtime prediction function using LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO upgrade the interpolation method for dailyData in the LSTM module\n",
    "fdd = dailyData['howMany'].interpolate(method='slinear',limit_direction='both')\n",
    "fdd = pd.DataFrame(fdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>howMany</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obsDt</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-03-23</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-24</th>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-25</th>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-26</th>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-27</th>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-06</th>\n",
       "      <td>12.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-07</th>\n",
       "      <td>12.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-08</th>\n",
       "      <td>12.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-09</th>\n",
       "      <td>12.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-10</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1084 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              howMany\n",
       "obsDt                \n",
       "2019-03-23   5.000000\n",
       "2019-03-24   4.600000\n",
       "2019-03-25   4.200000\n",
       "2019-03-26   3.800000\n",
       "2019-03-27   3.400000\n",
       "...               ...\n",
       "2022-03-06  12.714286\n",
       "2022-03-07  12.785714\n",
       "2022-03-08  12.857143\n",
       "2022-03-09  12.928571\n",
       "2022-03-10  13.000000\n",
       "\n",
       "[1084 rows x 1 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trainTest(dailyObs):\n",
    "    train, test = dailyObs[1:-327],dailyObs[-328:-6]\n",
    "    train = np.array(np.split(train,len(train)/7))\n",
    "    test = np.array(np.split(test,len(test)/7))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 7, 1)\n",
      "(46, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "train, test = split_trainTest(dailyObs=fdd)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build forward-moving windows\n",
    "def to_supervised(train,nInput,nOut = 7):\n",
    "    train = train.reshape((train.shape[0]*train.shape[1],train.shape[2]))\n",
    "    X, y = [],[]\n",
    "    inStart = 0\n",
    "    for _ in range(len(train)):\n",
    "        inEnd = inStart + nInput\n",
    "        outEnd = inEnd + nOut\n",
    "        if outEnd <= len(train):\n",
    "            xIn = train[inStart:inEnd,0]\n",
    "            xIn = xIn.reshape((len(xIn),1))\n",
    "            X.append(xIn)\n",
    "            y.append(train[inEnd:outEnd,0])\n",
    "        inStart+= 1\n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(743, 7, 1)\n",
      "(743, 7)\n"
     ]
    }
   ],
   "source": [
    "X, y = to_supervised(train=train,nInput=7)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(train,nInput):\n",
    "    train_x,train_y = to_supervised(train,nInput)\n",
    "    verbose, epochs, batch_size = 0,70,16\n",
    "    nTimesteps,nFeatures,nOutputs = train_x.shape[1],train_x.shape[2],train_y.shape[1]\n",
    "    model = Sequential()\n",
    "    #model.add(Bidirectional(LSTM(units=200,activation='relu')))\n",
    "    model.add(LSTM(units=200,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(nOutputs))\n",
    "    model.compile(loss='mse',optimizer='adam')\n",
    "    model.fit(train_x,train_y,epochs=epochs,batch_size=batch_size,verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model,history,nInput):\n",
    "    histData = np.array(history)\n",
    "    #histData = np.array(np.split(histData,len(histData)/7))\n",
    "    histData = histData.reshape((histData.shape[0]*histData.shape[1],histData.shape[2]))\n",
    "    inputX = histData[-nInput:,0]\n",
    "    inputX = inputX.reshape((1,len(inputX),1))\n",
    "    yhat = model.predict(inputX,verbose=0)\n",
    "    yhat = yhat[0]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_forecasts(actual,predicted):\n",
    "    try:\n",
    "        scores = list()\n",
    "        for i in range(actual.shape[1]):\n",
    "            mse = mean_squared_error(actual[:,i],predicted[:,i])\n",
    "            rmse = np.sqrt(mse)\n",
    "            scores.append(rmse)\n",
    "        s = 0\n",
    "        for row in range(actual.shape[0]):\n",
    "            for col in range(actual.shape[1]):\n",
    "                s+= (actual[row,col] - predicted[row,col])**2\n",
    "        score = np.sqrt(s/(actual.shape[0]*actual.shape[1]))\n",
    "    except Exception as metricExc:\n",
    "        raise metricExc\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalModel(train,test,nInput):\n",
    "    model = buildModel(train=train,nInput=nInput)\n",
    "    history = [x for x in train]\n",
    "    predictions = []\n",
    "    for i in range(len(test)):\n",
    "        yhatSeq = forecast(model=model,history=history,nInput=nInput)\n",
    "        predictions.append(yhatSeq)\n",
    "        history.append(test[i,:])\n",
    "    predictions = np.array(predictions)\n",
    "    score, scores = eval_forecasts(actual=test[:,:,0],predicted=predictions)\n",
    "    return score, scores\n",
    "    #return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, scores = evalModel(train=train,test=test,nInput=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeEvalScore(name,score,scores):\n",
    "    sScores = ', '.join(['%f' % s for s in scores])\n",
    "    print('%s: [%.3f] %s' % (name, score, sScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run: [2.442] 0.468001, 1.068273, 1.803750, 2.283598, 2.770545, 3.216125, 3.727616\n"
     ]
    }
   ],
   "source": [
    "summarizeEvalScore(name='run',score=score,scores=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. run1: [2.551] 2.458957, 2.472114, 2.475770, 2.677192, 3.045214, 2.251491, 2.402137 n = 7\n",
    "2. run2: [2.655] 2.482476, 2.564362, 2.557338, 2.738337, 3.200391, 2.457562, 2.509320 n = 21\n",
    "3. run3: [3.221] 2.561701, 2.617324, 2.715710, 3.185073, 3.910806, 3.548933, 3.717976 n = 14\n",
    "4. run4: [2.757] 2.647477, 2.664606, 2.711631, 2.933634, 3.188165, 2.496027, 2.599233 n = 7 bidirectional\n",
    "5. run5: [2.216] 0.385453, 0.939606, 1.419237, 1.818103, 2.423542, 2.977693, 3.646165 n = 7 note: changed interpolation method to slinear\n",
    "6. run6: [2.442] 0.468001, 1.068273, 1.803750, 2.283598, 2.770545, 3.216125, 3.727616"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce2b8b10e8082f390f0f7c9c12f304c9df3ed4554edd4b21c0fcee2d9ef65582"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
