{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as db\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score,explained_variance_score\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_userName = 'Tanag3r'\n",
    "ebird_token = 'j6c7l80ga2ib'\n",
    "db_name = 'trailheadDirectBirds_sous.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##connect to database\n",
    "def connectDB():\n",
    "    try:\n",
    "        cnx = db.connect(db_name)\n",
    "    except Exception as cnxError:\n",
    "        raise UserWarning(f'Unable to connect to database due to: {cnxError}')\n",
    "    return cnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopQualityMask(speciesCode: str,closestStop: str):\n",
    "    cnx = connectDB()\n",
    "    try:\n",
    "        gap = dt.date.today().year-2018\n",
    "        query = f'SELECT COUNT(DISTINCT(year)) as \"frq\" FROM coefficients_bySpecies WHERE speciesCode = \"{speciesCode}\" AND closestStop = \"{closestStop}\"'\n",
    "        coeficients = pd.read_sql(query,con=cnx)\n",
    "        coeficients['frq'] = coeficients.apply(lambda g: (g.frq/gap),axis=1)\n",
    "    except Exception as maskExc:\n",
    "        raise maskExc\n",
    "    return coeficients['frq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_stopMetrics(speciesCode,key,testBlob,latestUpdate):\n",
    "    cnx = connectDB()\n",
    "    cur = cnx.cursor()\n",
    "    try:\n",
    "        sqliteInsert = \"\"\"INSERT INTO stopMetricsBlob (speciesCode,key,testBlob,latestUpdate) VALUES (?,?,?,?);\"\"\"\n",
    "        logTuple = (speciesCode,key,testBlob,latestUpdate)\n",
    "        cur.execute(sqliteInsert,logTuple)\n",
    "        cnx.commit()\n",
    "        cur.close()\n",
    "    except db.Error as sqlError:\n",
    "        raise sqlError\n",
    "    finally:\n",
    "        if cnx:\n",
    "            cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline request from the application layer\n",
    "#outputs a list of birds at the stop and a classification based solely off the number of observations\n",
    "def birdList_request(StopName: str,cnx):\n",
    "    try:\n",
    "        query = f'SELECT speciesCode,count(subId) as \"checklists\",(SELECT count(subId) FROM historicObservations hxobx WHERE hxobx.speciesCode=hsob.speciesCode) as \"sightings\" FROM historicObservations hsob LEFT JOIN closestStop on hsob.locId=closestStop.locId WHERE StopName = \"{StopName}\" GROUP BY speciesCode;'\n",
    "        sightings = pd.read_sql(sql=query,con=cnx)\n",
    "    #rareness at the stop\n",
    "        sightings['stopGroup'] = int\n",
    "        bucket = sightings['checklists'].quantile([0,0.15,0.5,0.85,1])\n",
    "        sightings.loc[sightings['checklists'] <= bucket[0.15],'stopGroup'] = 1  #mythic\n",
    "        sightings.loc[(sightings['checklists'] > bucket[0.15]) & (sightings['checklists'] <= bucket[0.5]),'stopGroup'] = 2  #rare\n",
    "        sightings.loc[(sightings['checklists'] > bucket[0.5]) & (sightings['checklists'] < bucket[0.85]),'stopGroup'] = 3   #uncommon\n",
    "        sightings.loc[(sightings['checklists'] >= bucket[0.85]) & (sightings['checklists'] <=bucket[1]),'stopGroup'] = 4    #common\n",
    "    #overall rareness\n",
    "        sightings['overall'] = int\n",
    "        bucket = sightings['sightings'].quantile([0,0.15,0.5,0.85,1])\n",
    "        sightings.loc[sightings['sightings'] <= bucket[0.15],'overall'] = 1\n",
    "        sightings.loc[(sightings['sightings'] > bucket[0.15]) & (sightings['sightings'] <= bucket[0.5]),'overall'] = 2\n",
    "        sightings.loc[(sightings['sightings'] > bucket[0.5]) & (sightings['sightings'] < bucket[0.85]),'overall'] = 3\n",
    "        sightings.loc[(sightings['sightings'] >= bucket[0.85]) & (sightings['sightings'] <=bucket[1]),'overall'] = 4\n",
    "        sightings['StopName'] = StopName\n",
    "    #raise an exception if the stopName given is not valid and return a list of valid stop names\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return sightings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdlist = birdList_request(StopName='EastSunsetWay',cnx=connectDB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speciesCode</th>\n",
       "      <th>checklists</th>\n",
       "      <th>sightings</th>\n",
       "      <th>stopGroup</th>\n",
       "      <th>overall</th>\n",
       "      <th>StopName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>ruckin</td>\n",
       "      <td>28</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>EastSunsetWay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speciesCode  checklists  sightings stopGroup overall       StopName\n",
       "80      ruckin          28        113         4       3  EastSunsetWay"
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birdlist[birdlist['speciesCode'] == 'ruckin']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For birds with robust data, do they behave the same at all stops? If not, what stops does each species appear to prefer? Is that preference explained by habitat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO #92 change over flat annual average to weekly average in wklyAbd_selectSpecies() and other calcs\n",
    "def wklyAbd_selectSpecies(cnx,speciesList: list):\n",
    "    cnx=cnx\n",
    "    try:\n",
    "        querySpecies = []\n",
    "        for i in speciesList:\n",
    "            i = str(i)\n",
    "            querySpecies.append(i)\n",
    "        querySpecies = str(querySpecies).strip('[]')\n",
    "        #query = f'SELECT speciesCode,FX.locId,StopName,obsDt,howMany FROM historicObservations AS FX  LEFT JOIN closestStop on FX.locId = closestStop.locId WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.locId in ({query_locIds})'\n",
    "    #call baseline\n",
    "        queryBaseline = f'SELECT speciesCode,obsDt,howMany FROM historicObservations WHERE speciesCode in ({querySpecies})'\n",
    "        baseline = pd.read_sql(sql=queryBaseline,con=cnx,parse_dates=['obsDt'])\n",
    "        baseline = baseline.assign(obsDt_week=baseline.obsDt.dt.isocalendar().week)\n",
    "        baseline['howMany'].fillna(1,inplace=True)\n",
    "        baselineAvg = baseline.groupby(['speciesCode'])['howMany'].mean()\n",
    "\n",
    "        query = f'SELECT speciesCode,FX.locId,StopName,obsDt,howMany FROM historicObservations AS FX LEFT JOIN closestStop on FX.locId = closestStop.locId WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.speciesCode in ({querySpecies});'\n",
    "        obsData = pd.read_sql(query,con=cnx,parse_dates=['obsDt'])\n",
    "        obsData = obsData.assign(obsDt_week=obsData.obsDt.dt.isocalendar().week)\n",
    "        obsData['howMany'].fillna(1,inplace=True)\n",
    "        obsData = obsData.groupby(['speciesCode','StopName','obsDt_week'])['howMany'].mean().reset_index()\n",
    "    #compute relative abundance\n",
    "        obsData['relativeAbundance'] = obsData.apply(lambda x: (x.howMany/baselineAvg[x.speciesCode]),axis=1)  #baseline relative abd, same process as Fink et. all\n",
    "        #obsData['relativeAbundance'] = obsData.apply(lambda f: stopQualityMask(f.speciesCode,f.StopName)*f.relativeAbundance,axis=1)  #apply frequency mask\n",
    "        #avgAbd = obsData.groupby(['speciesCode'])['relativeAbundance'].mean()\n",
    "        #obsData['relativeAbundance'] = obsData.apply(lambda n: ((n.relativeAbundance)/(avgAbd[n.speciesCode])),axis=1)  #normalizing around average relative abundance\n",
    "        obsData.sort_values(by=['StopName','obsDt_week'],ascending=True,inplace=True)\n",
    "    except db.DatabaseError as dbExc:\n",
    "        raise f'there was an issue with the database request: {dbExc}'\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    finally: cnx.close()\n",
    "    return obsData[['obsDt_week','speciesCode','StopName','relativeAbundance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruckin = wklyAbd_selectSpecies(cnx=connectDB(),speciesList=['ruckin'])\n",
    "ruckin = ruckin[ruckin['StopName']=='EastSunsetWay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriveInterpolationMethod(obsData:pd.DataFrame):\n",
    "    try:\n",
    "        testResults = []\n",
    "        methodDict = [{'method':'linear','order':3,'limit_direction':'both'},{'method':'slinear','order':3,'limit_direction':'both'},{'method':'quadratic','order':0,'limit_direction':'both'},{'method':'cubic','order':3,'limit_direction':'both'},{'method':'spline','order':3,'limit_direction':'both'},{'method':'spline','order':5,'limit_direction':'both'},{'method':'polynomial','order':3,'limit_direction':'both'},{'method':'polynomial','order':5,'limit_direction':'both'},{'method':'barycentric','order':5,'limit_direction':'both'}]\n",
    "        small_methodDict = [{'method':'linear','order':0,'limit_direction':'both'},{'method':'slinear','order':3,'limit_direction':'both'},{'method':'polynomial','order':3,'limit_direction':'both'},{'method':'quadratic','order':0,'limit_direction':'both'}]\n",
    "        stopKeys = obsData['StopName'].drop_duplicates()\n",
    "        for x in stopKeys:\n",
    "            stop_obsData = obsData\n",
    "            allweek = pd.DataFrame({'obsDt_week':range(1,53)})\n",
    "            stop_obsData = pd.merge(left=allweek,left_on='obsDt_week',right=stop_obsData,right_on='obsDt_week',how='left')\n",
    "        #mask\n",
    "            stop_obsData['mask'] = stop_obsData['relativeAbundance'].interpolate(method='ffill',limit=4,limit_direction='forward')\n",
    "            stop_obsData['mask'] = stop_obsData['mask'].interpolate(method='bfill',limit=2,limit_direction='backward')\n",
    "            stop_obsData.loc[stop_obsData['mask'].isna() == True,'relativeAbundance'] = 0\n",
    "            stop_obsData = stop_obsData[stop_obsData['relativeAbundance'].notna()].drop(columns=['mask'])\n",
    "            for v in list([0.2,0.25,0.3,0.35]):\n",
    "                stop_obsData['sample'] = stop_obsData['relativeAbundance'].sample(frac=v,random_state=1)\n",
    "                if stop_obsData['sample'].count() < 4:\n",
    "                    chosen = small_methodDict\n",
    "                else: chosen = methodDict\n",
    "            else:\n",
    "                for test in chosen:\n",
    "                    testName = str(test['method'])\n",
    "                    stop_obsData[testName] = stop_obsData['sample']\n",
    "                    stop_obsData[testName] = stop_obsData['sample'].interpolate(method=test['method'],order=test['order'],limit_direction=test['limit_direction']).fillna(stop_obsData['relativeAbundance'])\n",
    "                    r_sqr = r2_score(y_true=stop_obsData['relativeAbundance'],y_pred=stop_obsData[testName],multioutput='variance_weighted')\n",
    "                    if r_sqr < 0:\n",
    "                        continue\n",
    "                    else: blob = {'StopName':x,'method':test['method'],'order':test['order'],'sampleSize':v,'r_sqr':r_sqr}\n",
    "                    testResults.append(blob)\n",
    "        resultFrame = pd.DataFrame.from_dict(testResults)\n",
    "        resultFrame = resultFrame.groupby(by=['StopName','method','order'])['r_sqr'].mean().reset_index()\n",
    "        resultFrame.sort_values(by=['StopName','r_sqr'],ascending=False,inplace=True)\n",
    "        resultFrame.drop_duplicates(subset=['StopName'],keep='first',inplace=True)\n",
    "                #stop_obsData.rename(columns={'sample':test['method']},inplace=True)\n",
    "    ##TODO #93 for each stop, return the best interpolation method as determined by the r2 score\n",
    "\n",
    "    except Exception as problem:\n",
    "        raise problem\n",
    "    return resultFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes a dataframe and returns a dictionary containing the best method and order value\n",
    "def deriveInterpolationMethod(obsData:pd.DataFrame):\n",
    "    try:\n",
    "        testResults = []\n",
    "        methodDict = [{'method':'linear','order':3,'limit_direction':'both'},{'method':'slinear','order':3,'limit_direction':'both'},{'method':'quadratic','order':0,'limit_direction':'both'},{'method':'cubic','order':3,'limit_direction':'both'},{'method':'spline','order':3,'limit_direction':'both'},{'method':'spline','order':5,'limit_direction':'both'},{'method':'polynomial','order':3,'limit_direction':'both'},{'method':'polynomial','order':5,'limit_direction':'both'},{'method':'barycentric','order':5,'limit_direction':'both'}]\n",
    "        small_methodDict = [{'method':'linear','order':0,'limit_direction':'both'},{'method':'slinear','order':3,'limit_direction':'both'},{'method':'polynomial','order':3,'limit_direction':'both'},{'method':'quadratic','order':0,'limit_direction':'both'}]\n",
    "            \n",
    "        stop_obsData = obsData\n",
    "        allweek = pd.DataFrame({'obsDt_week':range(1,53)})\n",
    "        stop_obsData = pd.merge(left=allweek,left_on='obsDt_week',right=stop_obsData,right_on='obsDt_week',how='left')\n",
    "    #mask\n",
    "        stop_obsData['mask'] = stop_obsData['relativeAbundance'].interpolate(method='ffill',limit=4,limit_direction='forward')\n",
    "        stop_obsData['mask'] = stop_obsData['mask'].interpolate(method='bfill',limit=2,limit_direction='backward')\n",
    "        stop_obsData.loc[stop_obsData['mask'].isna() == True,'relativeAbundance'] = 0\n",
    "        stop_obsData = stop_obsData[stop_obsData['relativeAbundance'].notna()].drop(columns=['mask'])\n",
    "        for v in list([0.2,0.25,0.3,0.35]):\n",
    "            stop_obsData['sample'] = stop_obsData['relativeAbundance'].sample(frac=v,random_state=1)\n",
    "            if stop_obsData['sample'].count() < 4:\n",
    "                chosen = small_methodDict\n",
    "            else: chosen = methodDict\n",
    "            for test in chosen:\n",
    "                testName = str(test['method'])\n",
    "                stop_obsData[testName] = stop_obsData['sample']\n",
    "                stop_obsData[testName] = stop_obsData['sample'].interpolate(method=test['method'],order=test['order'],limit_direction=test['limit_direction']).fillna(stop_obsData['relativeAbundance'])\n",
    "                r_sqr = r2_score(y_true=stop_obsData['relativeAbundance'],y_pred=stop_obsData[testName],multioutput='variance_weighted')\n",
    "                if r_sqr < 0:\n",
    "                    continue\n",
    "                else: blob = {'StopName':x,'method':test['method'],'order':test['order'],'sampleSize':v,'r_sqr':r_sqr}\n",
    "                blob = {'StopName':x,'method':test['method'],'order':test['order'],'sampleSize':v,'r_sqr':r_sqr}\n",
    "                testResults.append(blob)\n",
    "                resultFrame = pd.DataFrame.from_dict(testResults)\n",
    "        resultFrame = resultFrame.groupby(by=['method','order'])['r_sqr'].median().reset_index()\n",
    "        resultFrame.sort_values(by=['r_sqr'],ascending=False,inplace=True,ignore_index=True)\n",
    "        #resultFrame.drop_duplicates(subset=['StopName'],keep='first',inplace=True)\n",
    "                #stop_obsData.rename(columns={'sample':test['method']},inplace=True)\n",
    "    ##TODO #93 for each stop, return the best interpolation method as determined by the r2 score\n",
    "\n",
    "    except Exception as problem:\n",
    "        raise problem\n",
    "    return resultFrame.loc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>order</th>\n",
       "      <th>r_sqr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slinear</td>\n",
       "      <td>3</td>\n",
       "      <td>0.940618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quadratic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.921620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>3</td>\n",
       "      <td>0.921068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cubic</td>\n",
       "      <td>3</td>\n",
       "      <td>0.897658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>polynomial</td>\n",
       "      <td>3</td>\n",
       "      <td>0.897658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spline</td>\n",
       "      <td>3</td>\n",
       "      <td>0.476861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       method  order     r_sqr\n",
       "0     slinear      3  0.940618\n",
       "1   quadratic      0  0.921620\n",
       "2      linear      3  0.921068\n",
       "3       cubic      3  0.897658\n",
       "4  polynomial      3  0.897658\n",
       "5      spline      3  0.476861"
      ]
     },
     "execution_count": 969,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruckin_week = deriveInterpolationMethod(ruckin)\n",
    "ruckin_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'slinear', 'order': 3, 'r_sqr': 0.9406177020279693}"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruckin_week.loc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO #90 rewrite stopCovariance to run for a single species at a time --DONE\n",
    "\n",
    "def stopCovariance(obsData: pd.DataFrame,species: str,StopKey: str,cnx):\n",
    "    try:\n",
    "        obsData.sort_values(by=['StopName','obsDt_week'],ascending=True,inplace=True)\n",
    "        container = []\n",
    "        resultsContainer = []\n",
    "        stopKeys = obsData.drop_duplicates(subset=['StopName'])\n",
    "        for StopName in stopKeys.itertuples():\n",
    "            stop_obsData = obsData[obsData['speciesCode']==species]\n",
    "            stop_obsData = stop_obsData[stop_obsData['StopName']==StopName.StopName]\n",
    "            allweek = pd.DataFrame({'obsDt_week':range(1,53)})\n",
    "            stop_obsData.drop(columns=['speciesCode','StopName'],inplace=True)\n",
    "            stop_obsData = pd.merge(left=stop_obsData,right=allweek,left_on='obsDt_week',right_on='obsDt_week',how='outer')\n",
    "            stop_obsData.set_index('obsDt_week',inplace=True)\n",
    "            stop_obsData.sort_index(axis='index',ascending=True,inplace=True)\n",
    "        #TODO #91 write interpolation switches dependent on rarity for stopCovariance()\n",
    "            stop_obsData['mask'] = stop_obsData['relativeAbundance'].interpolate(method='ffill',limit=5,limit_direction='forward')  #mask, values do not matter\n",
    "            stop_obsData['mask'] = stop_obsData['mask'].interpolate(method='bfill',limit=2,limit_direction='backward')  #mask, values do not matter\n",
    "            stop_obsData.loc[stop_obsData['mask'].isna() == True,'relativeAbundance'] = 0\n",
    "            stop_obsData['fx_relativeAbundance'] = stop_obsData['relativeAbundance'].interpolate(method='linear',limit=5,limit_direction='forward')\n",
    "            stop_obsData['fx_relativeAbundance'] = stop_obsData['fx_relativeAbundance'].interpolate(method='linear',limit=2,limit_direction='backward')\n",
    "\n",
    "            stop_obsData.drop(columns=['relativeAbundance','mask'],inplace=True)\n",
    "            stop_obsData.rename(columns={'fx_relativeAbundance':StopName.StopName},inplace=True)              \n",
    "            container.append(stop_obsData)\n",
    "        weeklySpeciesAbd = pd.concat(container,ignore_index=False,axis=1)\n",
    "        weeklySpeciesAbd = weeklySpeciesAbd.fillna(value=0,axis=0)\n",
    "        weeklySpeciesAbd = weeklySpeciesAbd.apply(lambda n:(np.log1p(n)),axis=1)\n",
    "        y_true = weeklySpeciesAbd[StopKey]\n",
    "    #return related stops\n",
    "        fit = [(stop,r2_score(y_true,weeklySpeciesAbd[stop])) for stop in list(weeklySpeciesAbd)]\n",
    "        rSqr = filter(lambda r: (r[1] > 0.25) and (r[1]<1),fit)\n",
    "        var = [(stop,explained_variance_score(y_true,weeklySpeciesAbd[stop])) for stop in list(weeklySpeciesAbd)]\n",
    "        expVar = filter(lambda e: (e[1]>0.25) and (e[1]<1),var)\n",
    "        blob = {'rSquared':list(rSqr),'explVar':list(expVar)}\n",
    "        log_stopMetrics(speciesCode=species,key=StopKey,testBlob=str(blob),latestUpdate=str(dt.datetime.today()))\n",
    "\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return {'speciesCode':species,'stopKey':StopKey,'rSquared':list(rSqr),'explVar':list(expVar)}\n",
    "    #return y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "amerob = wklyAbd_selectSpecies(cnx=connectDB(),speciesList=['ruckin'])\n",
    "\n",
    "for x in list(amerob['StopName'].drop_duplicates()):\n",
    "    stopCovariance(obsData=amerob,species='ruckin',StopKey=x,cnx=connectDB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habitats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_habitat(cnx,distinctHabitats: int):\n",
    "    try:\n",
    "        data = pd.read_sql(sql='SELECT * FROM FAO_by_locId;',con=cnx)\n",
    "        data = data.drop(columns=['locName']).set_index('locId')\n",
    "        data.fillna(0,inplace=True)\n",
    "    #normalize\n",
    "        maxValue = data.apply(max,axis=1)\n",
    "        data = data.apply(lambda x: (x/maxValue[x.index]),axis=0)   #min-max normalizing to smooth in proportionality\n",
    "    #compute kmeans for each locId\n",
    "        habitat_kmeans = KMeans(n_clusters=distinctHabitats,init='k-means++')\n",
    "        habitat_kmeans = habitat_kmeans.fit(data.values)\n",
    "        clusterLabels = habitat_kmeans.labels_\n",
    "    #define habitats\n",
    "        habitatFrame = pd.DataFrame(data=clusterLabels,columns=['clusterLabel'],index=data.index).sort_values(by='clusterLabel').reset_index()\n",
    "        habitatFrame = pd.merge(left=habitatFrame,left_on='locId',right=data,right_on='locId',how='left')\n",
    "    except Exception as kmeansExc:\n",
    "        raise kmeansExc\n",
    "    return habitatFrame     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wklyAbd_selectSpecies_locIds(cnx,speciesList: list,locIdList: list):\n",
    "    cnx=cnx\n",
    "    try:\n",
    "        querySpecies = []\n",
    "        for i in speciesList:\n",
    "            i = str(i)\n",
    "            querySpecies.append(i)\n",
    "        querySpecies = str(querySpecies).strip('[]')\n",
    "        queryLocs = []\n",
    "        for i in locIdList:\n",
    "            i = str(i)\n",
    "            queryLocs.append(i)\n",
    "        queryLocs = str(queryLocs).strip('[]')\n",
    "    #baseline\n",
    "        baseQuery = f'SELECT speciesCode,obsDt,howMany FROM historicObservations WHERE speciesCode in ({querySpecies});'\n",
    "        baseline = pd.read_sql(baseQuery,con=cnx,parse_dates=['obsDt'])\n",
    "        baseline = baseline.assign(obsDt_week=baseline.obsDt.dt.isocalendar().week)\n",
    "        baselineAvg = baseline.groupby(['speciesCode'])['howMany'].mean()\n",
    "        #query = f'SELECT speciesCode,FX.locId,StopName,obsDt,howMany FROM historicObservations AS FX  LEFT JOIN closestStop on FX.locId = closestStop.locId WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.speciesCode in ({querySpecies}) AND FX.locId IN ({queryLocs});'\n",
    "        query = f'SELECT speciesCode,FX.locId,obsDt,howMany FROM historicObservations AS FX WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.speciesCode in ({querySpecies}) AND FX.locId IN ({queryLocs});'\n",
    "        obsData = pd.read_sql(query,con=cnx,parse_dates=['obsDt'])\n",
    "        obsData = obsData.assign(obsDt_week=obsData.obsDt.dt.isocalendar().week)\n",
    "        obsData['howMany'].fillna(1,inplace=True)\n",
    "        obsData = obsData.groupby(['speciesCode','obsDt_week'])['howMany'].mean().reset_index()\n",
    "        #maxCount = obsData.groupby(['speciesCode'])['howMany'].max()\n",
    "        \n",
    "    #derive relative abundance\n",
    "        obsData['relativeAbundance'] = obsData.apply(lambda x: (x.howMany/baselineAvg[x.speciesCode]),axis=1)  #baseline relative abd, same process as Fink et. all\n",
    "    #obsData['relativeAbundance'] = obsData.apply(lambda f: stopQualityMask(f.speciesCode,f.StopName)*f.relativeAbundance,axis=1)  #apply frequency mask\n",
    "    #avgAnnualAbd = obsData.groupby(['speciesCode'])['relativeAbundance'].mean()\n",
    "    #obsData['relativeAbundance'] = obsData.apply(lambda n: ((n.relativeAbundance)/(avgAnnualAbd[n.speciesCode])),axis=1)  #normalizing around average relative abundance\n",
    "        #obsData.sort_values(by=['obsDt_week'],ascending=True,inplace=True)\n",
    "    except db.DatabaseError as dbExc:\n",
    "        raise f'there was an issue with the database request: {dbExc}'\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    finally: cnx.close()\n",
    "    return obsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusterLabel\n",
       "6               13\n",
       "0                9\n",
       "2                8\n",
       "1                5\n",
       "8                5\n",
       "9                5\n",
       "3                4\n",
       "7                3\n",
       "4                2\n",
       "5                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "habs = kmeans_habitat(cnx=connectDB(),distinctHabitats=10)\n",
    "habs.value_counts(subset=['clusterLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L8365620', 'L10445835', 'L3438602', 'L1924233', 'L3199734']"
      ]
     },
     "execution_count": 893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelList = habs[habs['clusterLabel']==8]\n",
    "labelZero = list(labelList['locId'])\n",
    "labelZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speciesCode</th>\n",
       "      <th>obsDt_week</th>\n",
       "      <th>howMany</th>\n",
       "      <th>relativeAbundance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gockin</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.377377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gockin</td>\n",
       "      <td>12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.377377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gockin</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.172172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gockin</td>\n",
       "      <td>16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.688689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gockin</td>\n",
       "      <td>17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.860861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gockin</td>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.344344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gockin</td>\n",
       "      <td>19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.344344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gockin</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.172172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gockin</td>\n",
       "      <td>50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.344344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speciesCode  obsDt_week  howMany  relativeAbundance\n",
       "0      gockin           1      8.0           1.377377\n",
       "1      gockin          12      8.0           1.377377\n",
       "2      gockin          14      1.0           0.172172\n",
       "3      gockin          16      4.0           0.688689\n",
       "4      gockin          17      5.0           0.860861\n",
       "5      gockin          18      2.0           0.344344\n",
       "6      gockin          19      2.0           0.344344\n",
       "7      gockin          42      1.0           0.172172\n",
       "8      gockin          50      2.0           0.344344"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = wklyAbd_selectSpecies_locIds(cnx=connectDB(),speciesList=['gockin'],locIdList=labelZero)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6951003903407413"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(((5.837-2.901)**2/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "gockin = amerob[amerob['speciesCode']=='gockin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (2,)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20892/2636719707.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamerob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (2,)"
     ]
    }
   ],
   "source": [
    "list(amerob[2,])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce2b8b10e8082f390f0f7c9c12f304c9df3ed4554edd4b21c0fcee2d9ef65582"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
