{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as db\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score,explained_variance_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import linear_model\n",
    "#from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_userName = 'Tanag3r'\n",
    "ebird_token = 'j6c7l80ga2ib'\n",
    "db_name = 'trailheadDirectBirds_sous.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##connect to database\n",
    "def connectDB():\n",
    "    try:\n",
    "        cnx = db.connect(db_name)\n",
    "    except Exception as cnxError:\n",
    "        raise UserWarning(f'Unable to connect to database due to: {cnxError}')\n",
    "    return cnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopQualityMask(speciesCode: str,closestStop: str):\n",
    "    cnx = connectDB()\n",
    "    try:\n",
    "        gap = dt.date.today().year-2018\n",
    "        query = f'SELECT COUNT(DISTINCT(year)) as \"frq\" FROM coefficients_bySpecies WHERE speciesCode = \"{speciesCode}\" AND closestStop = \"{closestStop}\"'\n",
    "        coeficients = pd.read_sql(query,con=cnx)\n",
    "        coeficients['frq'] = coeficients.apply(lambda g: (g.frq/gap),axis=1)\n",
    "    except Exception as maskExc:\n",
    "        raise maskExc\n",
    "    return coeficients['frq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_stopMetrics(speciesCode,key,testBlob,latestUpdate):\n",
    "    cnx = connectDB()\n",
    "    cur = cnx.cursor()\n",
    "    try:\n",
    "        sqliteInsert = \"\"\"INSERT INTO stopMetricsBlob (speciesCode,key,testBlob,latestUpdate) VALUES (?,?,?,?);\"\"\"\n",
    "        logTuple = (speciesCode,key,testBlob,latestUpdate)\n",
    "        cur.execute(sqliteInsert,logTuple)\n",
    "        cnx.commit()\n",
    "        cur.close()\n",
    "    except db.Error as sqlError:\n",
    "        raise sqlError\n",
    "    finally:\n",
    "        if cnx:\n",
    "            cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline request from the application layer\n",
    "#outputs a list of birds at the stop and a classification based solely off the number of observations\n",
    "def birdList_request(StopName: str,cnx):\n",
    "    try:\n",
    "        query = f'SELECT speciesCode,count(subId) as \"checklists\",(SELECT count(subId) FROM historicObservations hxobx WHERE hxobx.speciesCode=hsob.speciesCode) as \"sightings\" FROM historicObservations hsob LEFT JOIN closestStop on hsob.locId=closestStop.locId WHERE StopName = \"{StopName}\" GROUP BY speciesCode;'\n",
    "        sightings = pd.read_sql(sql=query,con=cnx)\n",
    "    #rareness at the stop\n",
    "        sightings['stopGroup'] = int\n",
    "        bucket = sightings['checklists'].quantile([0,0.15,0.5,0.85,1])\n",
    "        sightings.loc[sightings['checklists'] <= bucket[0.15],'stopGroup'] = 1  #mythic\n",
    "        sightings.loc[(sightings['checklists'] > bucket[0.15]) & (sightings['checklists'] <= bucket[0.5]),'stopGroup'] = 2  #rare\n",
    "        sightings.loc[(sightings['checklists'] > bucket[0.5]) & (sightings['checklists'] < bucket[0.85]),'stopGroup'] = 3   #uncommon\n",
    "        sightings.loc[(sightings['checklists'] >= bucket[0.85]) & (sightings['checklists'] <=bucket[1]),'stopGroup'] = 4    #common\n",
    "    #overall rareness\n",
    "        sightings['overall'] = int\n",
    "        bucket = sightings['sightings'].quantile([0,0.15,0.5,0.85,1])\n",
    "        sightings.loc[sightings['sightings'] <= bucket[0.15],'overall'] = 1\n",
    "        sightings.loc[(sightings['sightings'] > bucket[0.15]) & (sightings['sightings'] <= bucket[0.5]),'overall'] = 2\n",
    "        sightings.loc[(sightings['sightings'] > bucket[0.5]) & (sightings['sightings'] < bucket[0.85]),'overall'] = 3\n",
    "        sightings.loc[(sightings['sightings'] >= bucket[0.85]) & (sightings['sightings'] <=bucket[1]),'overall'] = 4\n",
    "        sightings['StopName'] = StopName\n",
    "    #raise an exception if the stopName given is not valid and return a list of valid stop names\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return sightings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For birds with robust data, do they behave the same at all stops? If not, what stops does each species appear to prefer? Is that preference explained by habitat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO #92 change over flat annual average to weekly average in wklyAbd_selectSpecies() and other calcs\n",
    "def wklyAbd_selectSpecies(cnx,speciesList: list):\n",
    "    cnx=cnx\n",
    "    try:\n",
    "        querySpecies = []\n",
    "        for i in speciesList:\n",
    "            i = str(i)\n",
    "            querySpecies.append(i)\n",
    "        querySpecies = str(querySpecies).strip('[]')\n",
    "        #query = f'SELECT speciesCode,FX.locId,StopName,obsDt,howMany FROM historicObservations AS FX  LEFT JOIN closestStop on FX.locId = closestStop.locId WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.locId in ({query_locIds})'\n",
    "    #call baseline\n",
    "        queryBaseline = f'SELECT speciesCode,obsDt,howMany FROM historicObservations WHERE speciesCode in ({querySpecies})'\n",
    "        baseline = pd.read_sql(sql=queryBaseline,con=cnx,parse_dates=['obsDt'])\n",
    "        baseline = baseline.assign(obsDt_week=baseline.obsDt.dt.isocalendar().week)\n",
    "        baseline['howMany'].fillna(1,inplace=True)\n",
    "        baselineAvg = baseline.groupby(['speciesCode'])['howMany'].mean()\n",
    "\n",
    "        query = f'SELECT speciesCode,FX.locId,StopName,obsDt,howMany FROM historicObservations AS FX LEFT JOIN closestStop on FX.locId = closestStop.locId WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.speciesCode in ({querySpecies});'\n",
    "        obsData = pd.read_sql(query,con=cnx,parse_dates=['obsDt'])\n",
    "        obsData = obsData.assign(obsDt_week=obsData.obsDt.dt.isocalendar().week)\n",
    "        obsData['howMany'].fillna(1,inplace=True)\n",
    "        obsData = obsData.groupby(['speciesCode','StopName','obsDt_week'])['howMany'].mean().reset_index()\n",
    "    #compute relative abundance\n",
    "        obsData['relativeAbundance'] = obsData.apply(lambda x: (x.howMany/baselineAvg[x.speciesCode]),axis=1)  #baseline relative abd, same process as Fink et. all\n",
    "        #obsData['relativeAbundance'] = obsData.apply(lambda f: stopQualityMask(f.speciesCode,f.StopName)*f.relativeAbundance,axis=1)  #apply frequency mask\n",
    "        #avgAbd = obsData.groupby(['speciesCode'])['relativeAbundance'].mean()\n",
    "        #obsData['relativeAbundance'] = obsData.apply(lambda n: ((n.relativeAbundance)/(avgAbd[n.speciesCode])),axis=1)  #normalizing around average relative abundance\n",
    "        obsData.sort_values(by=['StopName','obsDt_week'],ascending=True,inplace=True)\n",
    "    except db.DatabaseError as dbExc:\n",
    "        raise f'there was an issue with the database request: {dbExc}'\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    finally: cnx.close()\n",
    "    return obsData[['obsDt_week','speciesCode','StopName','relativeAbundance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [],
   "source": [
    "westan = wklyAbd_selectSpecies(cnx=connectDB(),speciesList=['westan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = westan.apply(lambda x: bool(x.StopName=='ChiricoTrail_PooPooPoint') or bool(x.StopName=='MountTeneriffe'),axis=1)\n",
    "westan_lasso = westan[limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {},
   "outputs": [],
   "source": [
    "westan_lasso = westan[['obsDt_week','relativeAbundance']]\n",
    "westan_lasso = westan_lasso.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.],\n",
       "       [25.],\n",
       "       [26.],\n",
       "       [30.],\n",
       "       [19.],\n",
       "       [22.],\n",
       "       [26.],\n",
       "       [28.],\n",
       "       [33.],\n",
       "       [19.],\n",
       "       [20.],\n",
       "       [22.],\n",
       "       [24.],\n",
       "       [25.],\n",
       "       [27.],\n",
       "       [28.],\n",
       "       [30.],\n",
       "       [18.],\n",
       "       [19.],\n",
       "       [20.],\n",
       "       [22.],\n",
       "       [24.],\n",
       "       [26.],\n",
       "       [28.],\n",
       "       [29.],\n",
       "       [32.],\n",
       "       [23.],\n",
       "       [26.],\n",
       "       [27.],\n",
       "       [19.],\n",
       "       [21.],\n",
       "       [22.],\n",
       "       [23.],\n",
       "       [25.],\n",
       "       [28.],\n",
       "       [31.],\n",
       "       [35.]])"
      ]
     },
     "execution_count": 1227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = westan_lasso[:,:-1], westan_lasso[:,-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([50.43430631, 47.03520286, 43.86518761, 40.90882077, 38.15170317,\n",
       "        35.58040607, 33.18240578, 30.94602269, 28.86036433, 26.91527237,\n",
       "        25.10127309, 23.4095313 , 21.83180724, 20.3604165 , 18.98819257,\n",
       "        17.70845194, 16.51496155, 15.40190841, 14.36387134, 13.39579448,\n",
       "        12.49296277, 11.65097889, 10.86574191, 10.13342727,  9.45046819,\n",
       "         8.81353826,  8.21953528,  7.66556611,  7.14893261,  6.66711848,\n",
       "         6.21777701,  5.79871965,  5.40790535,  5.04343063,  4.70352029,\n",
       "         4.38651876,  4.09088208,  3.81517032,  3.55804061,  3.31824058,\n",
       "         3.09460227,  2.88603643,  2.69152724,  2.51012731,  2.34095313,\n",
       "         2.18318072,  2.03604165,  1.89881926,  1.77084519,  1.65149615,\n",
       "         1.54019084,  1.43638713,  1.33957945,  1.24929628,  1.16509789,\n",
       "         1.08657419,  1.01334273,  0.94504682,  0.88135383,  0.82195353,\n",
       "         0.76655661,  0.71489326,  0.66671185,  0.6217777 ,  0.57987196,\n",
       "         0.54079054,  0.50434306,  0.47035203,  0.43865188,  0.40908821,\n",
       "         0.38151703,  0.35580406,  0.33182406,  0.30946023,  0.28860364,\n",
       "         0.26915272,  0.25101273,  0.23409531,  0.21831807,  0.20360416,\n",
       "         0.18988193,  0.17708452,  0.16514962,  0.15401908,  0.14363871,\n",
       "         0.13395794,  0.12492963,  0.11650979,  0.10865742,  0.10133427,\n",
       "         0.09450468,  0.08813538,  0.08219535,  0.07665566,  0.07148933,\n",
       "         0.06667118,  0.06217777,  0.0579872 ,  0.05407905,  0.05043431]),\n",
       " array([[9.17679127e-18, 2.54442943e-03, 4.92906923e-03, 7.16323810e-03,\n",
       "         9.25580240e-03, 1.12151861e-02, 1.30493825e-02, 1.47659667e-02,\n",
       "         1.63721097e-02, 1.78745926e-02, 1.92798220e-02, 2.05938446e-02,\n",
       "         2.18223634e-02, 2.29707524e-02, 2.40440725e-02, 2.50470861e-02,\n",
       "         2.59842722e-02, 2.68598408e-02, 2.76777468e-02, 2.84417037e-02,\n",
       "         2.91551968e-02, 2.98214955e-02, 3.04436659e-02, 3.10245820e-02,\n",
       "         3.15669368e-02, 3.20732532e-02, 3.25458937e-02, 3.29870701e-02,\n",
       "         3.33988525e-02, 3.37831782e-02, 3.41418593e-02, 3.44765908e-02,\n",
       "         3.47889579e-02, 3.50804426e-02, 3.53524302e-02, 3.56062156e-02,\n",
       "         3.58430088e-02, 3.60639406e-02, 3.62700673e-02, 3.64623756e-02,\n",
       "         3.66417873e-02, 3.68091633e-02, 3.69653074e-02, 3.71109703e-02,\n",
       "         3.72468529e-02, 3.73736096e-02, 3.74918512e-02, 3.76021480e-02,\n",
       "         3.77050323e-02, 3.78010009e-02, 3.78905176e-02, 3.79740151e-02,\n",
       "         3.80518972e-02, 3.81245408e-02, 3.81922977e-02, 3.82554960e-02,\n",
       "         3.83144419e-02, 3.83694210e-02, 3.84207000e-02, 3.84685275e-02,\n",
       "         3.85131355e-02, 3.85547406e-02, 3.85935446e-02, 3.86297360e-02,\n",
       "         3.86634905e-02, 3.86949720e-02, 3.87243335e-02, 3.87517176e-02,\n",
       "         3.87772575e-02, 3.88010771e-02, 3.88232924e-02, 3.88440113e-02,\n",
       "         3.88633346e-02, 3.88813562e-02, 3.88981637e-02, 3.89138390e-02,\n",
       "         3.89284582e-02, 3.89420925e-02, 3.89548083e-02, 3.89666673e-02,\n",
       "         3.89777273e-02, 3.89880421e-02, 3.89976619e-02, 3.90066335e-02,\n",
       "         3.90150006e-02, 3.90228040e-02, 3.90300815e-02, 3.90368686e-02,\n",
       "         3.90431983e-02, 3.90491016e-02, 3.90546070e-02, 3.90597414e-02,\n",
       "         3.90645299e-02, 3.90689956e-02, 3.90731605e-02, 3.90770446e-02,\n",
       "         3.90806670e-02, 3.90840453e-02, 3.90871959e-02, 3.90901342e-02]]),\n",
       " array([ 0.00000000e+00,  0.00000000e+00,  7.10542736e-15,  7.10542736e-15,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  7.10542736e-15, -7.10542736e-15, -3.55271368e-15,\n",
       "         1.06581410e-14,  7.10542736e-15,  7.10542736e-15,  0.00000000e+00,\n",
       "         3.55271368e-15,  0.00000000e+00, -3.55271368e-15,  7.10542736e-15,\n",
       "         0.00000000e+00,  3.55271368e-15, -7.10542736e-15, -7.10542736e-15,\n",
       "        -7.10542736e-15,  1.06581410e-14, -3.55271368e-15, -3.55271368e-15,\n",
       "         0.00000000e+00,  3.55271368e-15, -3.55271368e-15, -1.06581410e-14,\n",
       "        -7.10542736e-15, -3.55271368e-15,  3.55271368e-15, -7.10542736e-15,\n",
       "        -1.06581410e-14, -3.55271368e-15, -7.10542736e-15, -1.42108547e-14,\n",
       "        -3.55271368e-15,  0.00000000e+00,  0.00000000e+00, -7.10542736e-15,\n",
       "         3.55271368e-15,  3.55271368e-15,  0.00000000e+00,  1.06581410e-14,\n",
       "         1.77635684e-14,  1.06581410e-14,  0.00000000e+00,  1.06581410e-14,\n",
       "         3.55271368e-15,  0.00000000e+00, -3.55271368e-15,  1.06581410e-14,\n",
       "         3.55271368e-15,  1.06581410e-14,  1.42108547e-14, -3.55271368e-15,\n",
       "         3.55271368e-15,  0.00000000e+00, -3.55271368e-15,  1.42108547e-14,\n",
       "         1.42108547e-14,  7.10542736e-15,  1.77635684e-14,  3.55271368e-15,\n",
       "         7.10542736e-15,  0.00000000e+00,  0.00000000e+00, -3.55271368e-15,\n",
       "         3.55271368e-15,  0.00000000e+00,  3.55271368e-15, -7.10542736e-15,\n",
       "        -3.55271368e-15,  3.55271368e-15,  3.55271368e-15,  0.00000000e+00,\n",
       "        -3.55271368e-15, -7.10542736e-15, -3.55271368e-15,  7.10542736e-15,\n",
       "        -7.10542736e-15, -3.55271368e-15,  1.06581410e-14, -3.55271368e-15,\n",
       "         0.00000000e+00, -1.42108547e-14,  3.55271368e-15, -7.10542736e-15,\n",
       "        -1.42108547e-14, -7.10542736e-15,  0.00000000e+00,  0.00000000e+00,\n",
       "        -3.55271368e-15, -7.10542736e-15, -7.10542736e-15, -1.42108547e-14]))"
      ]
     },
     "execution_count": 1223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl.path(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes a dataframe and returns a dictionary containing the best method and order value\n",
    "def deriveInterpolationMethod(obsData):\n",
    "    try:\n",
    "\n",
    "        testResults = []\n",
    "        methodDict = [{'method':'linear','order':3,'limit_direction':'both','limit':5},{'method':'slinear','order':3,'limit_direction':'both','limit':5},{'method':'quadratic','order':0,'limit_direction':'both','limit':5},{'method':'cubic','order':3,'limit_direction':'both','limit':5},{'method':'spline','order':3,'limit_direction':'both','limit':5},{'method':'spline','order':5,'limit_direction':'both','limit':5},{'method':'polynomial','order':3,'limit_direction':'both','limit':5},{'method':'polynomial','order':5,'limit_direction':'both','limit':5},{'method':'barycentric','order':5,'limit_direction':'both','limit':5}]\n",
    "        small_methodDict = [{'method':'linear','order':0,'limit_direction':'both','limit':3},{'method':'slinear','order':3,'limit_direction':'both','limit':3},{'method':'polynomial','order':3,'limit_direction':'both','limit':3},{'method':'quadratic','order':0,'limit_direction':'both','limit':3}]\n",
    "            \n",
    "        stop_obsData = obsData\n",
    "        allweek = pd.DataFrame({'obsDt_week':range(1,53)})\n",
    "        stop_obsData = pd.merge(left=allweek,left_on='obsDt_week',right=stop_obsData,right_on='obsDt_week',how='left')\n",
    "    #mask\n",
    "        stop_obsData['mask'] = stop_obsData['relativeAbundance'].interpolate(method='ffill',limit=4,limit_direction='forward')\n",
    "        stop_obsData['mask'] = stop_obsData['mask'].interpolate(method='bfill',limit=2,limit_direction='backward')\n",
    "        stop_obsData.loc[stop_obsData['mask'].isna() == True,'relativeAbundance'] = 0\n",
    "        stop_obsData = stop_obsData[stop_obsData['relativeAbundance'].notna()].drop(columns=['mask'])\n",
    "        for v in list([0.2,0.25,0.3,0.35]):\n",
    "            stop_obsData['sample'] = stop_obsData['relativeAbundance'].sample(frac=v,random_state=1)\n",
    "            if stop_obsData['speciesCode'].count() < 4:\n",
    "                chosen = small_methodDict\n",
    "            else: chosen = methodDict\n",
    "            blob = {}\n",
    "            for test in chosen:\n",
    "                testName = str(test['method'])\n",
    "                stop_obsData[testName] = stop_obsData['sample']\n",
    "                stop_obsData[testName] = stop_obsData['sample'].interpolate(method=test['method'],order=test['order'],limit=test['limit'],limit_direction=test['limit_direction']).fillna(stop_obsData['relativeAbundance'])\n",
    "                r_sqr = r2_score(y_true=stop_obsData['relativeAbundance'],y_pred=stop_obsData[testName])\n",
    "                if r_sqr < 0:\n",
    "                    continue\n",
    "                blob = {'method':test['method'],'order':test['order'],'limit':test['limit'],'sampleSize':v,'r_sqr':r_sqr}\n",
    "                testResults.append(blob)\n",
    "        if not testResults:\n",
    "            testResults.append({'method':'nearest','order':0,'limit':2})\n",
    "            resultFrame = pd.DataFrame.from_dict(testResults)\n",
    "        else:\n",
    "            resultFrame = pd.DataFrame.from_dict(testResults)\n",
    "            resultFrame = resultFrame.groupby(by=['method','order','limit'])['r_sqr'].median().reset_index()\n",
    "            resultFrame.sort_values(by=['r_sqr'],ascending=False,inplace=True,ignore_index=True)\n",
    "        #resultFrame.drop_duplicates(subset=['StopName'],keep='first',inplace=True)\n",
    "                #stop_obsData.rename(columns={'sample':test['method']},inplace=True)\n",
    "    ##TODO #93 for each stop, return the best interpolation method as determined by the r2 score -- done\n",
    "\n",
    "    except Exception as problem:\n",
    "        raise problem\n",
    "    return resultFrame.loc[0].to_dict()\n",
    "    #return resultFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO #90 rewrite stopCovariance to run for a single species at a time --DONE\n",
    "\n",
    "def stopCovariance(obsData: pd.DataFrame,species: str,StopKey: str,cnx):\n",
    "    try:\n",
    "        obsData.sort_values(by=['StopName','obsDt_week'],ascending=True,inplace=True)\n",
    "        container = []\n",
    "        resultsContainer = []\n",
    "        stopKeys = obsData.drop_duplicates(subset=['StopName'])\n",
    "        for StopName in stopKeys.itertuples():\n",
    "            stop_obsData = obsData[obsData['speciesCode']==species]\n",
    "            stop_obsData = stop_obsData[stop_obsData['StopName']==StopName.StopName]\n",
    "\n",
    "            stop_obsData.set_index('obsDt_week',inplace=True)\n",
    "            stop_obsData.sort_index(axis='index',ascending=True,inplace=True)\n",
    "            method = deriveInterpolationMethod(stop_obsData)\n",
    "            allweek = pd.DataFrame({'obsDt_week':range(1,53)})\n",
    "            stop_obsData.drop(columns=['StopName'],inplace=True)\n",
    "            stop_obsData = pd.merge(left=stop_obsData,right=allweek,left_on='obsDt_week',right_on='obsDt_week',how='outer')\n",
    "            stop_obsData.set_index('obsDt_week',inplace=True)\n",
    "            stop_obsData.sort_index(axis='index',ascending=True,inplace=True)\n",
    "            stop_obsData['mask'] = stop_obsData['relativeAbundance'].interpolate(method='ffill',limit=5,limit_direction='forward')  #mask, values do not matter\n",
    "            stop_obsData['mask'] = stop_obsData['mask'].interpolate(method='bfill',limit=2,limit_direction='backward')  #mask, values do not matter\n",
    "            stop_obsData.loc[stop_obsData['mask'].isna() == True,'relativeAbundance'] = 0\n",
    "            stop_obsData['fx_relativeAbundance'] = stop_obsData['relativeAbundance'].interpolate(method=method['method'],order=method['order'],limit=method['limit'],limit_direction='both')\n",
    "            stop_obsData.drop(columns=['relativeAbundance','mask','speciesCode'],inplace=True)\n",
    "            stop_obsData.rename(columns={'fx_relativeAbundance':StopName.StopName},inplace=True)              \n",
    "            container.append(stop_obsData)\n",
    "        weeklySpeciesAbd = pd.concat(container,ignore_index=False,axis=1)\n",
    "        weeklySpeciesAbd = weeklySpeciesAbd.fillna(value=0,axis=0)\n",
    "        weeklySpeciesAbd = weeklySpeciesAbd.apply(lambda n:(np.log1p(n)),axis=1)\n",
    "        y_true = weeklySpeciesAbd[StopKey]\n",
    "    #return related stops\n",
    "        fit = [(stop,r2_score(y_true,weeklySpeciesAbd[stop])) for stop in list(weeklySpeciesAbd)]\n",
    "        rSqr = filter(lambda r: (r[1] > 0.25) and (r[1]<1),fit)\n",
    "        var = [(stop,explained_variance_score(y_true,weeklySpeciesAbd[stop])) for stop in list(weeklySpeciesAbd)]\n",
    "        expVar = filter(lambda e: (e[1]>0.25) and (e[1]<1),var)\n",
    "        blob = {'rSquared':list(rSqr),'explVar':list(expVar)}\n",
    "        log_stopMetrics(speciesCode=species,key=StopKey,testBlob=str(blob),latestUpdate=str(dt.datetime.today()))\n",
    "\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return {'speciesCode':species,'stopKey':StopKey,'rSquared':list(rSqr),'explVar':list(expVar)}\n",
    "    #return method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in list(westan['StopName'].drop_duplicates()):\n",
    "    stopCovariance(obsData=westan,species='westan',StopKey=x,cnx=connectDB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habitats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_habitat(cnx,distinctHabitats: int):\n",
    "    try:\n",
    "        data = pd.read_sql(sql='SELECT * FROM FAO_by_locId;',con=cnx)\n",
    "        data = data.drop(columns=['locName']).set_index('locId')\n",
    "        data.fillna(0,inplace=True)\n",
    "    #normalize\n",
    "        maxValue = data.apply(max,axis=1)\n",
    "        data = data.apply(lambda x: (x/maxValue[x.index]),axis=0)   #min-max normalizing to smooth in proportionality\n",
    "    #compute kmeans for each locId\n",
    "        habitat_kmeans = KMeans(n_clusters=distinctHabitats,init='k-means++')\n",
    "        habitat_kmeans = habitat_kmeans.fit(data.values)\n",
    "        clusterLabels = habitat_kmeans.labels_\n",
    "    #define habitats\n",
    "        habitatFrame = pd.DataFrame(data=clusterLabels,columns=['clusterLabel'],index=data.index).sort_values(by='clusterLabel').reset_index()\n",
    "        habitatFrame = pd.merge(left=habitatFrame,left_on='locId',right=data,right_on='locId',how='left')\n",
    "    except Exception as kmeansExc:\n",
    "        raise kmeansExc\n",
    "    return habitatFrame     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wklyAbd_selectSpecies_locIds(cnx,speciesList: list,locIdList: list):\n",
    "    cnx=cnx\n",
    "    try:\n",
    "        querySpecies = []\n",
    "        for i in speciesList:\n",
    "            i = str(i)\n",
    "            querySpecies.append(i)\n",
    "        querySpecies = str(querySpecies).strip('[]')\n",
    "        queryLocs = []\n",
    "        for i in locIdList:\n",
    "            i = str(i)\n",
    "            queryLocs.append(i)\n",
    "        queryLocs = str(queryLocs).strip('[]')\n",
    "    #baseline\n",
    "        baseQuery = f'SELECT speciesCode,obsDt,howMany FROM historicObservations WHERE speciesCode in ({querySpecies});'\n",
    "        baseline = pd.read_sql(baseQuery,con=cnx,parse_dates=['obsDt'])\n",
    "        baseline = baseline.assign(obsDt_week=baseline.obsDt.dt.isocalendar().week)\n",
    "        baselineAvg = baseline.groupby(['speciesCode'])['howMany'].mean()\n",
    "        #query = f'SELECT speciesCode,FX.locId,StopName,obsDt,howMany FROM historicObservations AS FX  LEFT JOIN closestStop on FX.locId = closestStop.locId WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.speciesCode in ({querySpecies}) AND FX.locId IN ({queryLocs});'\n",
    "        query = f'SELECT speciesCode,FX.locId,obsDt,howMany FROM historicObservations AS FX WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.speciesCode in ({querySpecies}) AND FX.locId IN ({queryLocs});'\n",
    "        obsData = pd.read_sql(query,con=cnx,parse_dates=['obsDt'])\n",
    "        obsData = obsData.assign(obsDt_week=obsData.obsDt.dt.isocalendar().week)\n",
    "        obsData['howMany'].fillna(1,inplace=True)\n",
    "        obsData = obsData.groupby(['speciesCode','obsDt_week'])['howMany'].mean().reset_index()\n",
    "        if obsData.empty == True:\n",
    "            obsData = pd.DataFrame.from_dict({'speciesCode':speciesList,'obsDt_week':1,'relativeAbundance':0.00})\n",
    "        #maxCount = obsData.groupby(['speciesCode'])['howMany'].max()\n",
    "        else:\n",
    "    #derive relative abundance\n",
    "            obsData['relativeAbundance'] = obsData.apply(lambda x: (x.howMany/baselineAvg[x.speciesCode]),axis=1)  #baseline relative abd, same process as Fink et. all\n",
    "    #obsData['relativeAbundance'] = obsData.apply(lambda f: stopQualityMask(f.speciesCode,f.StopName)*f.relativeAbundance,axis=1)  #apply frequency mask\n",
    "    #avgAnnualAbd = obsData.groupby(['speciesCode'])['relativeAbundance'].mean()\n",
    "    #obsData['relativeAbundance'] = obsData.apply(lambda n: ((n.relativeAbundance)/(avgAnnualAbd[n.speciesCode])),axis=1)  #normalizing around average relative abundance\n",
    "        #obsData.sort_values(by=['obsDt_week'],ascending=True,inplace=True)\n",
    "    except db.DatabaseError as dbExc:\n",
    "        raise f'there was an issue with the database request: {dbExc}'\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    finally: cnx.close()\n",
    "    return obsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusterLabel\n",
       "6               13\n",
       "0                9\n",
       "2                8\n",
       "1                5\n",
       "8                5\n",
       "9                5\n",
       "3                4\n",
       "7                3\n",
       "4                2\n",
       "5                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "habs = kmeans_habitat(cnx=connectDB(),distinctHabitats=10)\n",
    "habs.value_counts(subset=['clusterLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L285366', 'L571490']"
      ]
     },
     "execution_count": 1163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelList = habs[habs['clusterLabel']==5]\n",
    "labelZero = list(labelList['locId'])\n",
    "labelZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speciesCode</th>\n",
       "      <th>obsDt_week</th>\n",
       "      <th>relativeAbundance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gockin</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speciesCode  obsDt_week  relativeAbundance\n",
       "0      gockin           1                0.0"
      ]
     },
     "execution_count": 1166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = wklyAbd_selectSpecies_locIds(cnx=connectDB(),speciesList=['gockin'],locIdList=labelZero)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6951003903407413"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(((5.837-2.901)**2/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "gockin = amerob[amerob['speciesCode']=='gockin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso together related habitats and stops\n",
    "\n",
    "https://machinelearningmastery.com/lasso-regression-with-python/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce2b8b10e8082f390f0f7c9c12f304c9df3ed4554edd4b21c0fcee2d9ef65582"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
