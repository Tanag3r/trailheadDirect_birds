{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as db\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score,explained_variance_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import linear_model\n",
    "#from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_userName = 'Tanag3r'\n",
    "ebird_token = 'j6c7l80ga2ib'\n",
    "db_name = 'trailheadDirectBirds_sous.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##connect to database\n",
    "def connectDB():\n",
    "    try:\n",
    "        cnx = db.connect(db_name)\n",
    "    except Exception as cnxError:\n",
    "        raise UserWarning(f'Unable to connect to database due to: {cnxError}')\n",
    "    return cnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopQualityMask(speciesCode: str,closestStop: str):\n",
    "    cnx = connectDB()\n",
    "    try:\n",
    "        gap = dt.date.today().year-2018\n",
    "        query = f'SELECT COUNT(DISTINCT(year)) as \"frq\" FROM coefficients_bySpecies WHERE speciesCode = \"{speciesCode}\" AND closestStop = \"{closestStop}\"'\n",
    "        coeficients = pd.read_sql(query,con=cnx)\n",
    "        coeficients['frq'] = coeficients.apply(lambda g: (g.frq/gap),axis=1)\n",
    "    except Exception as maskExc:\n",
    "        raise maskExc\n",
    "    return coeficients['frq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_stopMetrics(speciesCode,key,testBlob,latestUpdate):\n",
    "    cnx = connectDB()\n",
    "    cur = cnx.cursor()\n",
    "    try:\n",
    "        sqliteInsert = \"\"\"INSERT INTO stopMetricsBlob (speciesCode,key,testBlob,latestUpdate) VALUES (?,?,?,?);\"\"\"\n",
    "        logTuple = (speciesCode,key,testBlob,latestUpdate)\n",
    "        cur.execute(sqliteInsert,logTuple)\n",
    "        cnx.commit()\n",
    "        cur.close()\n",
    "    except db.Error as sqlError:\n",
    "        raise sqlError\n",
    "    finally:\n",
    "        if cnx:\n",
    "            cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline request from the application layer\n",
    "#outputs a list of birds at the stop and a classification based solely off the number of observations\n",
    "def birdList_request(StopName: str,cnx):\n",
    "    try:\n",
    "        query = f'SELECT speciesCode,count(subId) as \"checklists\",(SELECT count(subId) FROM historicObservations hxobx WHERE hxobx.speciesCode=hsob.speciesCode) as \"sightings\" FROM historicObservations hsob LEFT JOIN closestStop on hsob.locId=closestStop.locId WHERE StopName = \"{StopName}\" GROUP BY speciesCode;'\n",
    "        sightings = pd.read_sql(sql=query,con=cnx)\n",
    "    #rareness at the stop\n",
    "        sightings['stopGroup'] = int\n",
    "        bucket = sightings['checklists'].quantile([0,0.15,0.5,0.85,1])\n",
    "        sightings.loc[sightings['checklists'] <= bucket[0.15],'stopGroup'] = 1  #mythic\n",
    "        sightings.loc[(sightings['checklists'] > bucket[0.15]) & (sightings['checklists'] <= bucket[0.5]),'stopGroup'] = 2  #rare\n",
    "        sightings.loc[(sightings['checklists'] > bucket[0.5]) & (sightings['checklists'] < bucket[0.85]),'stopGroup'] = 3   #uncommon\n",
    "        sightings.loc[(sightings['checklists'] >= bucket[0.85]) & (sightings['checklists'] <=bucket[1]),'stopGroup'] = 4    #common\n",
    "    #overall rareness\n",
    "        sightings['overall'] = int\n",
    "        bucket = sightings['sightings'].quantile([0,0.15,0.5,0.85,1])\n",
    "        sightings.loc[sightings['sightings'] <= bucket[0.15],'overall'] = 1\n",
    "        sightings.loc[(sightings['sightings'] > bucket[0.15]) & (sightings['sightings'] <= bucket[0.5]),'overall'] = 2\n",
    "        sightings.loc[(sightings['sightings'] > bucket[0.5]) & (sightings['sightings'] < bucket[0.85]),'overall'] = 3\n",
    "        sightings.loc[(sightings['sightings'] >= bucket[0.85]) & (sightings['sightings'] <=bucket[1]),'overall'] = 4\n",
    "        sightings['StopName'] = StopName\n",
    "    #raise an exception if the stopName given is not valid and return a list of valid stop names\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return sightings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM for common birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def eval_forecasts(actual,predicted):\n",
    "    try:\n",
    "        scores = list()\n",
    "        for i in range(actual.shape[1]):\n",
    "            mse = mean_squared_error(actual[:,i],predicted[:,i])\n",
    "            rmse = np.sqrt(mse)\n",
    "            scores.append(rmse)\n",
    "        s = 0\n",
    "        for row in range(actual.shape[0]):\n",
    "            for col in range(actual.shapre[1]):\n",
    "                s+= (actual[row,col] - predicted[row,col]**2)\n",
    "        score = np.sqrt(s/(actual.shape[0]*actual.shapre[1]))\n",
    "    except Exception as metricExc:\n",
    "        raise metricExc\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For birds with robust data, do they behave the same at all stops? If not, what stops does each species appear to prefer? Is that preference explained by habitat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO #92 change over flat annual average to weekly average in wklyAbd_selectSpecies() and other calcs\n",
    "def wklyAbd_selectSpecies(cnx,speciesList: list):\n",
    "    cnx=cnx\n",
    "    try:\n",
    "        querySpecies = []\n",
    "        for i in speciesList:\n",
    "            i = str(i)\n",
    "            querySpecies.append(i)\n",
    "        querySpecies = str(querySpecies).strip('[]')\n",
    "        #query = f'SELECT speciesCode,FX.locId,StopName,obsDt,howMany FROM historicObservations AS FX  LEFT JOIN closestStop on FX.locId = closestStop.locId WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.locId in ({query_locIds})'\n",
    "    #call baseline\n",
    "        queryBaseline = f'SELECT speciesCode,obsDt,howMany FROM historicObservations WHERE speciesCode in ({querySpecies})'\n",
    "        baseline = pd.read_sql(sql=queryBaseline,con=cnx,parse_dates=['obsDt'])\n",
    "        baseline = baseline.assign(obsDt_week=baseline.obsDt.dt.isocalendar().week)\n",
    "        baseline['howMany'].fillna(1,inplace=True)\n",
    "        baselineAvg = baseline.groupby(['speciesCode'])['howMany'].mean()\n",
    "\n",
    "        query = f'SELECT speciesCode,FX.locId,StopName,obsDt,howMany FROM historicObservations AS FX LEFT JOIN closestStop on FX.locId = closestStop.locId WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.speciesCode in ({querySpecies});'\n",
    "        obsData = pd.read_sql(query,con=cnx,parse_dates=['obsDt'])\n",
    "        obsData = obsData.assign(obsDt_week=obsData.obsDt.dt.isocalendar().week)\n",
    "        obsData['howMany'].fillna(1,inplace=True)\n",
    "        obsData = obsData.groupby(['speciesCode','StopName','obsDt_week'])['howMany'].mean().reset_index()\n",
    "    #compute relative abundance\n",
    "        obsData['relativeAbundance'] = obsData.apply(lambda x: (x.howMany/baselineAvg[x.speciesCode]),axis=1)  #baseline relative abd, same process as Fink et. all\n",
    "        #obsData['relativeAbundance'] = obsData.apply(lambda f: stopQualityMask(f.speciesCode,f.StopName)*f.relativeAbundance,axis=1)  #apply frequency mask\n",
    "        #avgAbd = obsData.groupby(['speciesCode'])['relativeAbundance'].mean()\n",
    "        #obsData['relativeAbundance'] = obsData.apply(lambda n: ((n.relativeAbundance)/(avgAbd[n.speciesCode])),axis=1)  #normalizing around average relative abundance\n",
    "        obsData.sort_values(by=['StopName','obsDt_week'],ascending=True,inplace=True)\n",
    "    except db.DatabaseError as dbExc:\n",
    "        raise f'there was an issue with the database request: {dbExc}'\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    finally: cnx.close()\n",
    "    return obsData[['obsDt_week','speciesCode','StopName','relativeAbundance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "metadata": {},
   "outputs": [],
   "source": [
    "westan = wklyAbd_selectSpecies(cnx=connectDB(),speciesList=['westan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes a dataframe and returns a dictionary containing the best method and order value\n",
    "def deriveInterpolationMethod(obsData):\n",
    "    try:\n",
    "\n",
    "        testResults = []\n",
    "        methodDict = [{'method':'linear','order':3,'limit_direction':'both','limit':5},{'method':'slinear','order':3,'limit_direction':'both','limit':5},{'method':'quadratic','order':0,'limit_direction':'both','limit':5},{'method':'cubic','order':3,'limit_direction':'both','limit':5},{'method':'spline','order':3,'limit_direction':'both','limit':5},{'method':'spline','order':5,'limit_direction':'both','limit':5},{'method':'polynomial','order':3,'limit_direction':'both','limit':5},{'method':'polynomial','order':5,'limit_direction':'both','limit':5},{'method':'barycentric','order':5,'limit_direction':'both','limit':5}]\n",
    "        small_methodDict = [{'method':'linear','order':0,'limit_direction':'both','limit':3},{'method':'slinear','order':3,'limit_direction':'both','limit':3},{'method':'polynomial','order':3,'limit_direction':'both','limit':3},{'method':'quadratic','order':0,'limit_direction':'both','limit':3}]\n",
    "            \n",
    "        stop_obsData = obsData\n",
    "        allweek = pd.DataFrame({'obsDt_week':range(1,53)})\n",
    "        stop_obsData = pd.merge(left=allweek,left_on='obsDt_week',right=stop_obsData,right_on='obsDt_week',how='left')\n",
    "    #mask\n",
    "        stop_obsData['mask'] = stop_obsData['relativeAbundance'].interpolate(method='ffill',limit=4,limit_direction='forward')\n",
    "        stop_obsData['mask'] = stop_obsData['mask'].interpolate(method='bfill',limit=2,limit_direction='backward')\n",
    "        stop_obsData.loc[stop_obsData['mask'].isna() == True,'relativeAbundance'] = 0\n",
    "        stop_obsData = stop_obsData[stop_obsData['relativeAbundance'].notna()].drop(columns=['mask'])\n",
    "        for v in list([0.2,0.25,0.3,0.35]):\n",
    "            stop_obsData['sample'] = stop_obsData['relativeAbundance'].sample(frac=v,random_state=1)\n",
    "            if stop_obsData['speciesCode'].count() < 4:\n",
    "                chosen = small_methodDict\n",
    "            else: chosen = methodDict\n",
    "            blob = {}\n",
    "            for test in chosen:\n",
    "                testName = str(test['method'])\n",
    "                stop_obsData[testName] = stop_obsData['sample']\n",
    "                stop_obsData[testName] = stop_obsData['sample'].interpolate(method=test['method'],order=test['order'],limit=test['limit'],limit_direction=test['limit_direction']).fillna(stop_obsData['relativeAbundance'])\n",
    "                r_sqr = r2_score(y_true=stop_obsData['relativeAbundance'],y_pred=stop_obsData[testName])\n",
    "                if r_sqr < 0:\n",
    "                    continue\n",
    "                blob = {'method':test['method'],'order':test['order'],'limit':test['limit'],'sampleSize':v,'r_sqr':r_sqr}\n",
    "                testResults.append(blob)\n",
    "        if not testResults:\n",
    "            testResults.append({'method':'nearest','order':0,'limit':2})\n",
    "            resultFrame = pd.DataFrame.from_dict(testResults)\n",
    "        else:\n",
    "            resultFrame = pd.DataFrame.from_dict(testResults)\n",
    "            resultFrame = resultFrame.groupby(by=['method','order','limit'])['r_sqr'].median().reset_index()\n",
    "            resultFrame.sort_values(by=['r_sqr'],ascending=False,inplace=True,ignore_index=True)\n",
    "        #resultFrame.drop_duplicates(subset=['StopName'],keep='first',inplace=True)\n",
    "                #stop_obsData.rename(columns={'sample':test['method']},inplace=True)\n",
    "    ##TODO #93 for each stop, return the best interpolation method as determined by the r2 score -- done\n",
    "\n",
    "    except Exception as problem:\n",
    "        raise problem\n",
    "    return resultFrame.loc[0].to_dict()\n",
    "    #return resultFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO #90 rewrite stopCovariance to run for a single species at a time --DONE\n",
    "\n",
    "def stopCovariance(obsData: pd.DataFrame,species: str,StopKey: str,cnx):\n",
    "    try:\n",
    "        obsData.sort_values(by=['StopName','obsDt_week'],ascending=True,inplace=True)\n",
    "        container = []\n",
    "        resultsContainer = []\n",
    "        stopKeys = obsData.drop_duplicates(subset=['StopName'])\n",
    "        for StopName in stopKeys.itertuples():\n",
    "            stop_obsData = obsData[obsData['speciesCode']==species]\n",
    "            stop_obsData = stop_obsData[stop_obsData['StopName']==StopName.StopName]\n",
    "\n",
    "            stop_obsData.set_index('obsDt_week',inplace=True)\n",
    "            stop_obsData.sort_index(axis='index',ascending=True,inplace=True)\n",
    "            method = deriveInterpolationMethod(stop_obsData)\n",
    "            allweek = pd.DataFrame({'obsDt_week':range(1,53)})\n",
    "            stop_obsData.drop(columns=['StopName'],inplace=True)\n",
    "            stop_obsData = pd.merge(left=stop_obsData,right=allweek,left_on='obsDt_week',right_on='obsDt_week',how='outer')\n",
    "            stop_obsData.set_index('obsDt_week',inplace=True)\n",
    "            stop_obsData.sort_index(axis='index',ascending=True,inplace=True)\n",
    "            stop_obsData['mask'] = stop_obsData['relativeAbundance'].interpolate(method='ffill',limit=5,limit_direction='forward')  #mask, values do not matter\n",
    "            stop_obsData['mask'] = stop_obsData['mask'].interpolate(method='bfill',limit=2,limit_direction='backward')  #mask, values do not matter\n",
    "            stop_obsData.loc[stop_obsData['mask'].isna() == True,'relativeAbundance'] = 0\n",
    "            stop_obsData['fx_relativeAbundance'] = stop_obsData['relativeAbundance'].interpolate(method=method['method'],order=method['order'],limit=method['limit'],limit_direction='both')\n",
    "            stop_obsData.drop(columns=['relativeAbundance','mask','speciesCode'],inplace=True)\n",
    "            stop_obsData.rename(columns={'fx_relativeAbundance':StopName.StopName},inplace=True)              \n",
    "            container.append(stop_obsData)\n",
    "        weeklySpeciesAbd = pd.concat(container,ignore_index=False,axis=1)\n",
    "        weeklySpeciesAbd = weeklySpeciesAbd.fillna(value=0,axis=0)\n",
    "        weeklySpeciesAbd = weeklySpeciesAbd.apply(lambda n:(np.log1p(n)),axis=1)\n",
    "        y_true = weeklySpeciesAbd[StopKey]\n",
    "    #return related stops\n",
    "        fit = [(stop,r2_score(y_true,weeklySpeciesAbd[stop])) for stop in list(weeklySpeciesAbd)]\n",
    "        rSqr = filter(lambda r: (r[1] > 0.25) and (r[1]<1),fit)\n",
    "        var = [(stop,explained_variance_score(y_true,weeklySpeciesAbd[stop])) for stop in list(weeklySpeciesAbd)]\n",
    "        expVar = filter(lambda e: (e[1]>0.25) and (e[1]<1),var)\n",
    "        blob = {'rSquared':list(rSqr),'explVar':list(expVar)}\n",
    "        log_stopMetrics(speciesCode=species,key=StopKey,testBlob=str(blob),latestUpdate=str(dt.datetime.today()))\n",
    "\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return {'speciesCode':species,'stopKey':StopKey,'rSquared':list(rSqr),'explVar':list(expVar)}\n",
    "    #return method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in list(westan['StopName'].drop_duplicates()):\n",
    "    stopCovariance(obsData=westan,species='westan',StopKey=x,cnx=connectDB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habitats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_habitat(cnx,distinctHabitats: int):\n",
    "    try:\n",
    "        data = pd.read_sql(sql='SELECT * FROM FAO_by_locId;',con=cnx)\n",
    "        data = data.drop(columns=['locName']).set_index('locId')\n",
    "        data.fillna(0,inplace=True)\n",
    "    #normalize\n",
    "        maxValue = data.apply(max,axis=1)\n",
    "        data = data.apply(lambda x: (x/maxValue[x.index]),axis=0)   #min-max normalizing to smooth in proportionality\n",
    "    #compute kmeans for each locId\n",
    "        habitat_kmeans = KMeans(n_clusters=distinctHabitats,init='k-means++')\n",
    "        habitat_kmeans = habitat_kmeans.fit(data.values)\n",
    "        clusterLabels = habitat_kmeans.labels_\n",
    "    #define habitats\n",
    "        habitatFrame = pd.DataFrame(data=clusterLabels,columns=['clusterLabel'],index=data.index).sort_values(by='clusterLabel').reset_index()\n",
    "        habitatFrame = pd.merge(left=habitatFrame,left_on='locId',right=data,right_on='locId',how='left')\n",
    "    except Exception as kmeansExc:\n",
    "        raise kmeansExc\n",
    "    return habitatFrame     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wklyAbd_selectSpecies_locIds(cnx,speciesList: list,locIdList: list):\n",
    "    cnx=cnx\n",
    "    try:\n",
    "        querySpecies = []\n",
    "        for i in speciesList:\n",
    "            i = str(i)\n",
    "            querySpecies.append(i)\n",
    "        querySpecies = str(querySpecies).strip('[]')\n",
    "        queryLocs = []\n",
    "        for i in locIdList:\n",
    "            i = str(i)\n",
    "            queryLocs.append(i)\n",
    "        queryLocs = str(queryLocs).strip('[]')\n",
    "    #baseline\n",
    "        baseQuery = f'SELECT speciesCode,obsDt,howMany FROM historicObservations WHERE speciesCode in ({querySpecies});'\n",
    "        baseline = pd.read_sql(baseQuery,con=cnx,parse_dates=['obsDt'])\n",
    "        baseline = baseline.assign(obsDt_week=baseline.obsDt.dt.isocalendar().week)\n",
    "        baselineAvg = baseline.groupby(['speciesCode'])['howMany'].mean()\n",
    "        #query = f'SELECT speciesCode,FX.locId,StopName,obsDt,howMany FROM historicObservations AS FX  LEFT JOIN closestStop on FX.locId = closestStop.locId WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.speciesCode in ({querySpecies}) AND FX.locId IN ({queryLocs});'\n",
    "        query = f'SELECT speciesCode,FX.locId,obsDt,howMany FROM historicObservations AS FX WHERE (SELECT count(distinct(subId)) FROM historicObservations AS QA WHERE QA.comName = FX.comName) > 2 AND FX.speciesCode in ({querySpecies}) AND FX.locId IN ({queryLocs});'\n",
    "        obsData = pd.read_sql(query,con=cnx,parse_dates=['obsDt'])\n",
    "        obsData = obsData.assign(obsDt_week=obsData.obsDt.dt.isocalendar().week)\n",
    "        obsData['howMany'].fillna(1,inplace=True)\n",
    "        obsData = obsData.groupby(['speciesCode','obsDt_week'])['howMany'].mean().reset_index()\n",
    "        if obsData.empty == True:\n",
    "            obsData = pd.DataFrame.from_dict({'speciesCode':speciesList,'obsDt_week':1,'relativeAbundance':0.00})\n",
    "        #maxCount = obsData.groupby(['speciesCode'])['howMany'].max()\n",
    "        else:\n",
    "    #derive relative abundance\n",
    "            obsData['relativeAbundance'] = obsData.apply(lambda x: (x.howMany/baselineAvg[x.speciesCode]),axis=1)  #baseline relative abd, same process as Fink et. all\n",
    "    #obsData['relativeAbundance'] = obsData.apply(lambda f: stopQualityMask(f.speciesCode,f.StopName)*f.relativeAbundance,axis=1)  #apply frequency mask\n",
    "    #avgAnnualAbd = obsData.groupby(['speciesCode'])['relativeAbundance'].mean()\n",
    "    #obsData['relativeAbundance'] = obsData.apply(lambda n: ((n.relativeAbundance)/(avgAnnualAbd[n.speciesCode])),axis=1)  #normalizing around average relative abundance\n",
    "        #obsData.sort_values(by=['obsDt_week'],ascending=True,inplace=True)\n",
    "    except db.DatabaseError as dbExc:\n",
    "        raise f'there was an issue with the database request: {dbExc}'\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    finally: cnx.close()\n",
    "    return obsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusterLabel\n",
       "6               13\n",
       "0                9\n",
       "2                8\n",
       "1                5\n",
       "8                5\n",
       "9                5\n",
       "3                4\n",
       "7                3\n",
       "4                2\n",
       "5                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "habs = kmeans_habitat(cnx=connectDB(),distinctHabitats=10)\n",
    "habs.value_counts(subset=['clusterLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L8312096',\n",
       " 'L4381196',\n",
       " 'L10129054',\n",
       " 'L424117',\n",
       " 'L7672326',\n",
       " 'L3943215',\n",
       " 'L6226126',\n",
       " 'L128530',\n",
       " 'L450305']"
      ]
     },
     "execution_count": 1247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelList = habs[habs['clusterLabel']==0]\n",
    "labelZero = list(labelList['locId'])\n",
    "labelZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speciesCode</th>\n",
       "      <th>obsDt_week</th>\n",
       "      <th>howMany</th>\n",
       "      <th>relativeAbundance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>westan</td>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>westan</td>\n",
       "      <td>19</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>3.808000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>westan</td>\n",
       "      <td>20</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>westan</td>\n",
       "      <td>22</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.597333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>westan</td>\n",
       "      <td>24</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>westan</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>westan</td>\n",
       "      <td>26</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>westan</td>\n",
       "      <td>28</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>westan</td>\n",
       "      <td>29</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>westan</td>\n",
       "      <td>30</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>westan</td>\n",
       "      <td>32</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>westan</td>\n",
       "      <td>33</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.896000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speciesCode  obsDt_week   howMany  relativeAbundance\n",
       "0       westan          18  1.000000           0.448000\n",
       "1       westan          19  8.500000           3.808000\n",
       "2       westan          20  2.000000           0.896000\n",
       "3       westan          22  1.333333           0.597333\n",
       "4       westan          24  2.000000           0.896000\n",
       "5       westan          25  1.000000           0.448000\n",
       "6       westan          26  3.000000           1.344000\n",
       "7       westan          28  3.000000           1.344000\n",
       "8       westan          29  3.000000           1.344000\n",
       "9       westan          30  1.000000           0.448000\n",
       "10      westan          32  3.000000           1.344000\n",
       "11      westan          33  2.000000           0.896000"
      ]
     },
     "execution_count": 1248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = wklyAbd_selectSpecies_locIds(cnx=connectDB(),speciesList=['westan'],locIdList=labelZero)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6951003903407413"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(((5.837-2.901)**2/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "gockin = amerob[amerob['speciesCode']=='gockin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use LASSO to cross validate KFold splits of training data.\n",
    "\n",
    "https://machinelearningmastery.com/lasso-regression-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce2b8b10e8082f390f0f7c9c12f304c9df3ed4554edd4b21c0fcee2d9ef65582"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
